
20170426
机器学习：（包含）
	supervised leaning 监督学习 ：根据 输入 预测 输出
		regression：预测结果
		classification：分类内容
	reinforcement leaning 强化学习： 做判断，决策
	unsupervised leaning 非监督学习：挖据有关输入的规律
人工智能 = 深度学习+强化学习    
强化学习 就是 训练最优大脑模型 实时训练 相当于人的最终大脑决策 判断， 
深度学习 相当于脑皮层 神经 对外部信息的处理。
	也称 supervised leaning 监督学习，
所以人工智能就是强化学习 加上深度学习 ，
比如alphaGo就是强化学习来负责决策，CNN来负责处理棋子 下棋位置的范围确定,MCTS树最后结合来搜索
这里讨论的是xxNN模型例子都是，深度学习的模型：
原理缥缈，直接学习使用 tensorflow 框架（做过alphago） 
下载安装 （只使用cpu，针对python2.7的版本）
sudo pip2 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
教程：
https://my.oschina.net/yilian/blog/664632
教程的范例都会在tensorflow_test里示范学习一遍
1,入门，线性拟合实验，linear_fitting_test.py
2,CNN卷积神经网络： CNN_test.py 
3,自修改的卷积神经网络： CNN_test2.py
4,使用可视化界面观察训练情况tensorboard，（安装tensorflow时就已经安装了）
	tensorboard --logdir=/tmp/logs
	Starting TensorBoard 16 on port 6006
	(You can navigate to http://0.0.0.0:6006)	//浏览器打开 http://0.0.0.0:6006 就可以开始监测
	但是要使用tensorboard监测，代码里也要做相对应的设置 CNN_test3_with_tensorboard.py
	出错，是关于tensorboard的api 的调用出现了问题，以后再处理！！
5，
9，RNN/LSTM循环神经网络长短期记忆网络使用 RNN_test.py
10,最强网络 RSNN深度残差网络 平均准确率96-99% RSNN_test.py 卡死出错












20170428
从最基本的例子 CNN_test.py 深入 深度学习的 基础原理和概念
import input_data	//下载了一个例子数据包，分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）。
			//是一个 用于识别阿拉伯数字图片 的例子数据包 （0~9十个阿拉伯数字） 
			//训练数据用于训练模型，测试数据和训练数据其实是相同内容，
			//但独立出来是避免使用曾经用于训练模型的数据来检测模型，更公平得到模型的准确性
mnist = input_data.read_data_sets("/tmp/data/", one_hot=True)
			//这里是读取这个数据包的数据
			//每个数据包有两个数据集，
			//每个数据集都有两部分组成，一个是图片包，一个是对应的标签包
			//训练数据集有一个含60000张图片的图片包，和对应一个含60000行便签的标签包
			//测试数据集有一个含10000张图片的图片包，和对应一个含10000行便签的标签包		
			//每张图片对应一个 10维向量的便签，比如说：
			//图片包第200张图片显示”5“，便签包第200条10维向量对应为 ([0,0,0,0,0,1,0,0,0,0])
最基础的学习原理（矩阵乘法方程）：
使用线性回归的方法，就是通过提供的样本来训练出一个可以描述样本行为的 矩阵乘法方程，也叫训练出一种合理的特定”思维“
例子数据包每张图片是 28X28 分辨率的黑白图片，那每张图片可以表示为 28x28 = 784 维向量 x，对应的标签为 y
我们引入一个可以用于描述特征的 10×784 矩阵W， 和偏移向量量b  还引入一个特征标签10维向量 Y 
执行矩阵乘法： Y = W × x + b  （经过多样本训练，得到合理的 矩阵乘法 方程，最终W 和b稳定到一定区域，这个过程也称拟合，）
	Y1      W11x1  + W12x2  + W13x3  + ..... W1784x784  + b1
	Y2      W21x1  + W22x2  + W23x3  + ..... W2784x784  + b2
	Y3      W31x1  + W32x2  + W33x3  + ..... W3784x784  + b3
	Y4      W41x1  + W42x2  + W43x3  + ..... W4784x784  + b4
	Y5   =  W51x1  + W52x2  + W53x3  + ..... W5784x784  + b5
	Y6      W61x1  + W62x2  + W63x3  + ..... W6784x784  + b6
	Y7      W71x1  + W72x2  + W73x3  + ..... W7784x784  + b7
	Y8      W81x1  + W82x2  + W83x3  + ..... W8784x784  + b8
	Y8      W91x1  + W92x2  + W93x3  + ..... W9784x784  + b9
	Y10     W101x1 + W102x2 + W103x3 + ..... W10784x784 + b10		
即一张图片 x 通过特征矩阵 W 处理后，提取到特征便签 Y
再把特征便签归一化的预测标签 y_ = softmax（Y）(不是归一化,是激活函数吧)
假如模型不断训练，特征矩阵 W 稳定到不需要改变，那么预测标签 y_ 与 x 对应的真实标签 y 应该一致！！！
如果不一致，y与y_就有误差，
通过统计误差，然后运用交叉熵等数学方法，得到修正量，反馈更新特征矩阵W和偏移向量b，
模型又进化成长了点，
通过不同图片 x 的训练 ，模型最终成长到一个接近完美的状态，这时，算出的y_与y极大多数一致，即表示模型基本能识别每一个图片上的数字
但仅仅y_与y一致，并不百分百认为识别对图片，
训练好的模型识别一张图片的过程是：
	得到图片的y_,y_与十中y中的一个吻合，基本确认图片数字与y对应的数字一样，
	然后模型继续取出 y 对应的那张暂存在模型里参照图片， 与正在识别的图片 执行布尔运算 （就是对俩个784维向量执行按维与运算）
	吻合程度超过75%，那么就完全确认正确图片上的数字！！！

欠拟合：训练出来的 矩阵乘法方程，与样本不能很好地吻合，不能很好形成合适的”思维“
过拟合：训练出来的的 矩阵乘法方程，只与已知的训练样本完全吻合，也不能形成合理的”思维“

加权回归：
	与线性回归的区别是，线性回归会考虑每一个样本，为训练出合适的 矩阵乘法方程 做贡献，
	而加权回归是，重视某部分样品对训练方程时的贡献，而忽略或减少某些样本对训练方程时的影响，所以训练的是变种 矩阵乘法方程

feedfroward模型神经网络:(FNN),而不是完整的CNN模型,对于CNN认识的补充有待讨论)：
	上述学习原理中，我们讲述是训练拟合一个合理的矩阵乘法方程（思维） Y = W × x + b，
		当这个 思维 被训练得相当成熟了，给机器 一个”信息：x“(这个x例如是28x28像素的整张图片)，根据 思维，机器做出一个”行为：y“
	这种思维只是一个 矩阵乘法方程，往往被视为思维简单，不管被训练得多久，最后应用时，做出的行为准确程度都不会太高！！
	如果现在改成以下方式：
	a1 = Wa1 × x + ba1，训练一个 向量乘法 方程提取抽象信息a1，即训练更新 特征向量Wa1，和偏移向量ba1
	a2 = Wa2 × x + ba2，训练一个 向量乘法 方程提取抽象信息a2，即训练更新 特征向量Wa2，和偏移向量ba2
	a3 = Wa3 × x + ba3，训练一个 向量乘法 方程提取抽象信息a3，即训练更新 特征向量Wa3，和偏移向量ba3
	a4 = Wa4 × x + ba4，训练一个 向量乘法 方程提取抽象信息a4，即训练更新 特征向量Wa4，和偏移向量ba4
	a5 = Wa5 × x + ba5，训练一个 向量乘法 方程提取抽象信息a5，即训练更新 特征向量Wa5，和偏移向量ba5
	可以看出，每个信息 x向量 都会得到 5个抽样信息组成的 a向量（a1,a2,a3,a4，a5）
	接着上述例子，一个样本信息集有60000个信息x，即60000个 x向量，就有60000个5维a向量
	然后继续：
	c1 = Wc1 × a + bc1，训练一个 向量乘法 方程提取抽象信息c1，即训练更新 特征向量Wc1，和偏移向量bc1
	c2 = Wc2 × a + bc2，训练一个 向量乘法 方程提取抽象信息c2，即训练更新 特征向量Wc2，和偏移向量bc2
	c3 = Wc3 × a + bc3，训练一个 向量乘法 方程提取抽象信息c3，即训练更新 特征向量Wc3，和偏移向量bc3
	c4 = Wc4 × a + bc4，训练一个 向量乘法 方程提取抽象信息c4，即训练更新 特征向量Wc4，和偏移向量bc4
	c5 = Wc5 × a + bc5，训练一个 向量乘法 方程提取抽象信息c5，即训练更新 特征向量Wc5，和偏移向量bc5
	c6 = Wc6 × a + bc6，训练一个 向量乘法 方程提取抽象信息c6，即训练更新 特征向量Wc6，和偏移向量bc6
	可以看出，每个a向量 都会得到 6个抽样信息组成的 c向量（c1,c2,c3,c4,c6）
	一个样本信息集有60000个信息x，就有60000个5维a向量，就有60000个6维c向量
	然后继续：
	Y = Wd × c + bd，训练一个 矩阵乘法 方程做出行为Y，即训练更新 特征矩阵Wd，和偏移向量bd
	最终通过抽象信息c做出行为Y
	比起简单的 x -> Y 思维，这里是 x -> a -> c -> Y 多层思维！
	每一个 向量乘法方程 视为一个神经元！
	那 5个 获取抽象信息a的 向量乘法方程 共同组成第一神经层
	那 6个 获取抽象信息c的 向量乘法方程 共同组成第二神经层
	每一条信息x 都处在输入层
	最后得到的行为Y 处在输出层
	那么：输入层x， 第一神经a， 第二神经层b， 输出层Y 组成的就是 一个神经网络
	发现每一层都是一个 矩阵方程组(多个向量方程组成一个矩阵方程组)
	上述是一个典型的神经网络例子，当然，实际的神经网络可以更多层，更复杂。
	一般矩阵乘法神经网络用于机械视觉，机械听觉类工作，例如识别图片内容，分析一首MP3属于什么类型音乐等等
	有一种改进的方法,可以减少计算复杂程度!!!
		就是对于上述的 所有 向量乘法方程 都加入同一个sigmond算子 或者 同一个tanh算子!!
		即都加 f(Z) = sigmond(z) 或者都加 f(z) = tanh(z)
		例如:
			a2 = f ( Wa2 × x + ba2 )
			....
			c5 = f ( Wc5 × a + bc5 )
			....
		如果是f()是tanh()这时得到的 a1,a2,....c1,c2,... 大部分要不是深度接近1,要深度接近近-1,即在[-1,1]区间
			即得到的a和c向量都偏简单比如: 向量a ={1,-0.9,1,0.8,-1},....
		如果是f()是sigmond这时得到的 a1,a2,....c1,c2,... 大部分要不是深度接近0,要深度接近近1,即在[0,1]区间
			即得到的a和c向量都偏简单比如: 向量a ={1,0.8,0,0.9,0},....
		这样再投入下一层网络的计算,计算量变得相当少,
		而且这种技巧被证明不影响模型的训练!!!
	还有一种算子叫 softmax() 与归一化相关的算子
	前向传导:就是上述的 向量x经一层层网络得到y
	反向传导:就是根据 实际推得y向量 和 预期y向量 的方差,往后修正网络中的各个W 和 b 的过程
				

卷积神经网络概念 （CNN）:
	参考:	http://blog.csdn.net/zkl99999/article/details/46805453
	   	https://www.zhihu.com/question/34681168
	现实中,的图片样品或者声音样品,如果使用传统的froward,那么就需要大量 矩阵方程,需要拟合大量的 大型W矩阵和b向量
	CNN的思想是:前期设立几层,通过卷积核提取样本特征!,最后得到多份的相互独立的特征碎片
		    后面的几层就是 统计和使用feedfroward模型等传统手段归类
	相比于feedfroward模型,
		CNN是多了一个提取出多份样本特征的过程,然后训练识别样本特征组成的输入向量.
		但是 feedfroward模型 ,直接把样本当成一个输入向量,然后训练,
		这么一比较就发现了 CNN 训练的时间成本低,而且,准确率不比feedfroward模型差!!
	一个重要的概念是 卷积核,其实就是一个nxn的小矩阵,
		卷积核用法:
			卷积核从样图片左上方开始,nxn卷积核 矩阵乘以 此刻所在nxn像素区域,
			得到的一个加权平均值,为新特征图的新的一个像素点!!
			(上述加权平均得到平均值的过程叫 卷积)
			然后卷积核在样图片向右移动一个像素点,重复动作得到新特征图第二个像素点...
			卷积核移动轨迹从左到右,从上到下
		使用例子:
		例如一张300x300的样图image,通过一个 5x5的卷积核换算,得到一张296x296 的特征图map
		第一层conv为A,有10个5x5卷积核,那么这张image对应A层就有 10张296x296特征图A_map
		第二层conv为B,有6个100x100卷积核,那么A层每张map在B层又分别有 6张193x193特征图B_map,理应60张B_map
			然而事实上不一定60张B_map,可以有限定有30张B_map,这就是说随机某些A_map并没有透过某些卷积核生成B_map
		第三层conv为C,有6个100x100卷积核,那么B层每张map在C层又分别有 6张92x92特征图C_map,理应共30x6=180张C_map
			然而只取其中60张C_map
		最后一层conv为D 有5个92x92卷积核,那么C层每张map在d层又分别有 5张1x1特征图D_map,理应共60x5=3000张D_map
			最后一层,会全部使用300张1x1特征图D_map,	
			由于1x1特征图,所以直接构造成 300维的向量,所以最后一层的这种变换叫做 全连接(full connecttion)
		以上就是取特征的过程,
		最后就类似 feedfroward模型 方法训练300维的向量!!! D层相当于输入层
		layer1 有 200 个300x1 向量方程,300维向量经过layer1 得到1个200维向量
		output 层 1  个200x50矩阵方程,最终得到一个 50维向量,
			归一化后最后指出图片里是一辆汽车
		统计以下 要训练的参数!!!
		A层(10x5x5)+10=260, B层(6x100x100)+6=60006, C层(6x100x100)+6=60006, D层(5x92x92)+5=8469
		layer1 300x200+200=60200, ouput 200x50+50=10050
		共 198991 个需要训练参数
	对比 feedfroward模型的一个例子!!!
		同样一张300x300的样图image,相当于300x300=90000维向量
		layer1 有 200 个90000x1向量方程,90000维向量经过layer1 得到1个200维向量
 		output 层 1  个200x50矩阵方程,最终得到一个 50维向量,
		统计以下 要训练的参数!!!
		layer1 90000x200+200=18000200, ouput 200x50+50=10050
		共 18010250 个需要训练的参数,
		即使不要 layer1,直接转成 50维向量,也要 90000x50+50=4500050个训练参数!!
		都比 CNN 训练的参数要多!!!	


循环神经网络概念 （RNN）：
	即过去的行为可以影响此刻行为的神经网络结构，以3层feedfroward神经模型 类比讲解 简单的3层经典RNN结构
	3层CNN即：输入层，第一层神经网络（假设只有4个神经元），输出层：从上述知道：
		第一神经网络对应的矩阵乘法方程有：
		a1 = Wa1 × x + ba1，训练一个矩阵乘法方程提取抽象信息a1，即训练更新特征矩阵Wa1，和偏移向量ba1
		a2 = Wa2 × x + ba2，训练一个矩阵乘法方程提取抽象信息a2，即训练更新特征矩阵Wa2，和偏移向量ba2
		a3 = Wa3 × x + ba3，训练一个矩阵乘法方程提取抽象信息a3，即训练更新特征矩阵Wa3，和偏移向量ba3
		a4 = Wa4 × x + ba4，训练一个矩阵乘法方程提取抽象信息a4，即训练更新特征矩阵Wa4，和偏移向量ba4
		输出层对应的矩阵乘法方程有：
		Y = Wc × a + bc，训练一个矩阵乘法方程做出行为Y，即训练更新特征矩阵Wc，和偏移向量bc
		经过训练后，经过这种传递关系 由x最终得到对应Y
	而 经典RNN 除了由此刻的x外，还又之前的x，共同得到此刻的 Y 的
		因此输入层 还是 x 不变
		第一神经网络对应的方程一般是这样，
		a1 = Wa1 × |x，<a-| + ba1，训练一个矩阵乘法方程提取抽象信息a1，即训练更新特征矩阵Wa1，和偏移向量ba1
		a2 = Wa2 × |x，<a-| + ba2，训练一个矩阵乘法方程提取抽象信息a2，即训练更新特征矩阵Wa2，和偏移向量ba2
		a3 = Wa3 × |x，<a-| + ba3，训练一个矩阵乘法方程提取抽象信息a3，即训练更新特征矩阵Wa3，和偏移向量ba3
		a4 = Wa4 × |x，<a-| + ba4，训练一个矩阵乘法方程提取抽象信息a4，即训练更新特征矩阵Wa4，和偏移向量ba4
		<a- 我暂且这样表示是 上一次的 x求Y 过程中 得到的的中间量 a（a1,a2,a3,a4）
		|x，<a-| 表示 x 与上一次的 a 的组成的矩阵
		也就说，除了输入层的x参数作为输入参数外，还有上次得到的a
		输出层对应的矩阵乘法方程有：
		Y = Wc × a + bc，训练一个矩阵乘法方程做出行为Y，即训练更新特征矩阵Wc，和偏移向量bc
		输出层的形式保持不变，就是这样子，使得上一次的输入直接影响到此刻行为的结果	 
	RNN的变种非常多，上述是最简单模型也是最没有应用前景的模型
	迄今应用最为广泛是RNN模型是基于 LSTM单元的模型
	参考：http://colah.github.io/posts/2015-08-Understanding-LSTMs/
	http://blog.csdn.net/Dark_Scope/article/details/47056361
	http://blog.csdn.net/u014595019/article/details/52605693
	重点是，之前的都是一个矩阵乘法方程作为一神经元
	但是lstm 使用多个矩阵乘法方程组成特殊神经元，其中有三个矩阵乘法方程作为“门”通过归一化后得到的1后0来判断是否输入 x 和 <a- 信息
		到神经元核的矩阵乘法方程，也判断是否传递到下一次的 工作循环去，


深度神经网络概念 （DNN）：
	这个概念比较广泛，其实就是各种基础神经网络的混合，还有往往是多层网络！！


///////以上介绍了一些基本模型,以下讨论如何反向修改模型参数达到 训练学习模型的目的!!////////

 (只是分辨是与不是)		参考:http://blog.csdn.net/u014595019/article/details/52554582
	顾名思义，逻辑分类，是一种二分类法，能将数据分成0和1两类
	几乎所有的教材都是从logistic分类开始的，因为logistic分类实在太经典，而且是神经网络的基本组成部分，
	每个神经元(cell)都可以看做是进行了一次logistic分类
	假设有一个n维的输入列向量 x，也有一个n维的参数横向量h， 还有一个偏置量b， 那么就可以线性求和得到一个数z.

		z = hx + b
	
	此时因为z的值域是 [−∞,+∞] ，是无法根据z来判断列向量 x 到底是属于0还是1的。
	我们需要一个函数，来将z的值映射到[0,1]之间，这就是激活函数。激活函数有很多种，这里把 z 代入的激活函数是sigmoid函数。

			    1
		σ(z) =	_________	即, a = σ(z) = σ( hx + b )		
			1 + e^(-z)	
	
	z在[−∞,0]时,a从0上升到0.5; z在[0,+∞]时,a从0.5上升到1
	当 a 大于0.5的时候，我们判定x应属于1类，如果小于0.5，则属于0类。这样，就完成了判断的工作
	注意这时 a值域是 [0,1],不是只有0和1两个值. 但是z域[−∞,-4]时,a几乎等于0, z域[4,+∞]时,a几乎等于1,
	所以可以有种错觉是 a 只有 0 和 1 两个值,
	可以知道,h和b的值直接关系到logistic判断的准确性,
	最开始的时候，h中的值是随机的，而b的值是0. 我们通过不断的训练来使得h和b能够尽可能的达到一个较优的值
	假设我们列向量 x 的期望判定是y,而实际得到的判定值是a, a值域是 [0,1],但是 y 一般就是 0和1两个值!!
	定义一个损失函数 C(y,a),记录y与a的差距,那么:

					∂C	∂C
	那么当参数修正量(参数的偏导数),	__ =0	__ =0	 这个最优条件达到时,C越靠近最小值0,
					∂h	∂b
	 h和b 也就靠近最优解,logistic判断的准确性也靠近百分百

	注意，迭代过程中，∂C/∂h， ∂C/∂b， 是对此刻的 h 和 b 值求偏导得到值，而不是去真接求 ∂C/∂h = 0， ∂C/∂b = 0 时，对应的 h 和 b 值。

				    ∂C		        ∂C
	通过不断迭代,	h = h − η * __ ,    b = b − η * __		h和b无限接近最优条件,logistic判断的准确性无限接近百分百
				    ∂h	 	        ∂b

	其中 η 表示学习率, 如果损失函数 C(y,a) 为平方损失函数: 	C = 1/2 (a−y)^2 	那么:

		∂C   ∂C   ∂a	     ∂σ(z)	   ∂σ(z)  ∂z
		__ = __ * __ = (a−y) _____ = (a−y) _____ ____ = (a−y)*σ′(z)*x = (a−y)*a*(1−a)x
		∂h   ∂a   ∂h	      ∂h	    ∂z    ∂h

		∂C
		__ = (a−y)*a*(1−a)
		∂b

	最后得到每次迭代的参数更新公式     
		h = h − η * (a−y) * a * (1−a) *x , 	
		b = b − η * (a−y) * a * (1−a)
logistic扩展(多样分类)
	譬如判断 某事物 是否是 3个类型中的一个,其实就是拆分成三个logistic分类,每个logistic分类都对这个食物判断是或者不是!!
	上面讨论时, a 只是一个数
	在这里我们可以列出一个列向量:	  [x,x,x]T   来表示 a,
	自然地,     y 也是一个列向量:	  [x,x,x]T
	那么,当
		a = y = [1,0,0]T	表示事物属于第一类
		a = y = [0,1,0]T	表示事物属于第二类
		a = y = [0,0,1]T	表示事物属于第三类
		a = y = [0,0,0]T	表示事物不属于任何一类
	自然地:本来的 logistic分类模型 扩展为:	
		z=Wx+b  
		a=σ(z)
	z是一个列向量,
	a是上上面谈论到的列向量
	W是矩阵,是三列 横向量 h 的组合,
	b是3个偏置量 组合的列向量!!
			⎡σ(z1) ⎤
			⎢σ(z2) ⎥
	而:	σ(z) =	⎢ ⋮     ⎥
			⎣σ(zn) ⎦
	最后同理的到参数修正量:(注意有些向量之间是进行点乘de ".*")

		∂C
		__ = (a−y) .* a .* (1−a) * xT
		∂W

		∂C
		__ = (a−y) .* a .* (1−a)
		∂b

以一个feedfroward如何反向传导,修改学习模型参数
	假设是一个 3层 feedfroward 模型
	输入层		隐藏层		输出层
	  x1		  ha1		  ya1
	  x2		  ha2		  ya2
	  x3		  ha3		  ya3
		⋮		⋮
	输入层是 列向量X（x1,x2,x3,,,）,
	隐藏层是 列限量ha（ha1,ha2,ha3,,,）,其中每个数值量haX，
		也代表着一个神经元，代表这一个 向量乘法如 ha1 = Whx1 * x + bh1
		其中 Whx1 是一个 行向量， bh1是一个偏移数值
	输出层是 列向量ya（ya1,ya2,ya3,,,）,
	所以这个三层模型 由两重 logistic扩展分类方法 组成：
		hz = Whx * x + bh 
		ha = σ(hz) 	//sigmoid函数,注意这是激活函数，不是归一化函数
		yz = Wyh * ha + by 
		ya = σ(yz)
	Whx 输入层到隐藏层的矩阵 多个 WhxX 行向量组成 , 
	bh 偏置向量 
	Wyh 隐藏层到输出层的矩阵 多个 WyhX 行向量组成, 
	by 偏置向量
	之前讨论过 feedfroward 的前向擦传导，现在讨论如何从的到的 ya 后向反导修正 Whx，bh，Wyh，by
	这里我们 设定使用的 损失函数依然是 差平和函数：    C = 1/2 ( ya − y)^2	其中 y 是期望值向量，ya是实际输出值向量
	则第二重 logistic扩展分类方法 的 参数修正量(参数的偏导数)有：

		∂C    ∂C    ∂ya
		___ = ___ * ___ = C′(ya) * σ′(yz) = (ya−y) .* a .*(1−a)
		∂yz   ∂ya   ∂yz
	
		 ∂C    ∂C    ∂yz
		____ = ___ * ____ = C′(ya) * σ′(yz) * haT 
		∂Wyh   ∂yz   ∂Wyh

		∂C    ∂C    ∂yz
		___ = ___ * ___ = C′(ya) * σ′(yz)
		∂by   ∂yz   ∂by

	类似地，第一重 logistic扩展分类方法 的 参数修正量有：
		
		∂C    ∂C    ∂yz
		___ = ___ * ___ = WyhT * [C′(ya) * σ′(yz)] 
		∂ha   ∂yz   ∂ha

		 ∂C    ∂C    ∂ha    ∂C    ∂ha    ∂hz      ∂C
		____ = ___ * ____ = ___ * ____ * ___  = [ ___ * σ′(hz) ] * xT
		∂Whx   ∂ha   ∂Whx   ∂ha   ∂hz    ∂Whx     ∂ha

		∂C    ∂C    ∂ha     ∂C
		___ = ___ * ___ = [ ___ * σ′(hz) ]
		∂bh   ∂ha   ∂bh     ∂ha

	可以看到，在 Whx 和 bh 的计算中都用到了 ∂C/∂ha 这可以看成由输出层传递到中间层的误差。
	那么在获得了各参数的偏导数以后，就可以对参数进行修正了 

			        ∂C
		Wyh = Wyh − η * ___  
			        ∂Wyh

			      ∂C
		by = by − η * ___ 
			      ∂by

				 ∂C
		Whx = Whx − η * ____   
				∂Whx

			      ∂C
		bh = bh − η * ___
			      ∂bh
	
	就这样得到修正量 反向修正了模型参数
激活函数	http://blog.csdn.net/u014595019/article/details/52562159
	激活函数的主要作用是提供网络的非线性建模能力。
	如果没有激活函数，那么该网络仅能够表达线性映射，此时即便有再多的隐藏层，其整个网络跟单层神经网络也是等价的！！
	因此也可以认为，只有加入了激活函数之后，深度神经网络才具备了分层的非线性映射学习能力
	就是说激活函数，本来就是可以不需要的！！！！
	激活函数不是线性代数里所说的归一化算术，
	激活函数的加入，可以锐化主要特征，而把很多无关紧要的细节模糊平滑掉！！
	激活函数应该具有什么样的性质：
		可微性： 当优化方法是基于梯度的时候，这个性质是必须的。
		单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。
		输出值的范围： 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加 稳定，
			因为特征的表示受有限权值的影响更显著;当激活函数的输出是 
			无限 的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate
	以下讨论的激活函数都未涉及向量！！
	sigmoid：

				   1
			f(x) = __________	
			       1 + e^(−x)

		sigmoid 是使用范围最广的一类激活函数，具有指数函数形状，它在物理意义上最为接近生物神经元。
		此外，(0, 1) 的输出还可以被表示作概率，或用于输入的归一化，代表性的如Sigmoid交叉熵损失函数。
		（图形见网络链接）
		sigmoid也有其自身的缺陷，最明显的就是饱和性。由于两则无穷接近 0 和 1，其两侧导数逐渐趋近于0 
			lim f′(x) = 0 	
			x−>∞
			具有这种性质的称为 软饱和激活函数。具体的，饱和又可分为左饱和与右饱和
		比较地，还有一个概念叫 硬饱和，特征为：
			f′(x) = 0，当|x|>c，（其中c为常数）
		在后向传递过程中，sigmoid向下传导的梯度包含了一个 f′(x) 因子（sigmoid关于输入的导数），
			因此一旦输入落入饱和区，f′(x) 就会变得接近于0，导致了向底层传递的梯度也变得非常小。
			此时，网络参数很难得到有效训练。这种现象被称为梯度消失。
			一般来说， sigmoid 网络在 5 层之内就会产生 梯度消失 现象
		此外，提出一个 输出均值 概念 :
			输出均值 指 把整个函数的[−∞,+∞]，积分得得到的值再做平均，
			sigmoid函数的输出都大于0，输出均值就不会是0，这种情况下称为 偏移现象，
			这会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。
			即 激活函数的输出都大于或等于0，称为偏移现象，
			当然 激活函数的输出都小于或等于0，也称为偏移现象，
		此外sigmod 与softmax 是不一样的！！
			softmax是归一函数，如果转换一个向量， 转换后向量的成员和为 1
			sigmod 如果转换一个向量， 转换后向量的成员不是 约等于1就是0！！

	tanh：

		       1 − e^(−2x)
		f(x) = ___________
		       1 + e^(−2x)

		图像特性 与 sigmoid 几乎一样,
		区别在值域在 [-1,1], x=0时，y=0。
		tanh 输出均值 = 0 
			所以，加入tanh的学习模型时，学习次数少，迭代次数少的情况也能达到显著效果
		tanh一样具有软饱和性，从而造成梯度消失。
		重申，梯度消失现象：指多层学习网络，无法，很难，或者几乎不能反向传导修正底层网络的参数，
			导致学习模型很难，甚至不能收敛！！
	
	ReLU：
		      /	x, if x≥0,
		f(x) = 			又可以写成： f(x) = max(0,x)
		      \	0, if x<0
		
		当x<0时，ReLU硬饱和，而当x>0时，则不存在饱和问题
		能够在x>0时保持梯度不衰减，从而缓解梯度消失问题
		这让我们能够直接以监督的方式训练深度神经网络，而无需依赖无监督的逐层预训练（这句话不明白）
		然而，随着训练的推进，部分输入会落入硬饱和区，导致对应权重无法更新。这种现象被称为“神经元死亡”。
		与sigmoid类似，ReLU的输出均值也大于0，偏移现象和 神经元死亡会共同影响网络的收敛性。
	
	Leaky-ReLU

		      / x, if x≥0,
		f(x) = 
		      \ α * x, if x<0,	α是一个常数！！

		针对在x<0的硬饱和问题的改进！！
	
	P-ReLU
	
		      / x, if x≥0,
		f(x) = 
		      \ α * x, if x<0,	α变化的

		针对在x<0的硬饱和问题的改进！！	
		α变化的意思是，对于当前的训练来说，α是常数，到了下一次训练，α改变为另一个常数

	ELU
	

		      / x, if x≥0
		f(x) = 
		      \ α * ( e^x − 1), if x<0

		融合了sigmoid和ReLU，左侧具有软饱和性，右侧无饱和性。
		右侧线性部分使得ELU能够缓解梯度消失
		左侧软饱能够让ELU对输入变化或噪声更好
		ELU的输出均值接近于零，所以收敛速度更快
		在 ImageNet上，不加 Batch Normalization 30 层以上的 ReLU 网络会无法收敛，
		PReLU网络在MSRA的Fan-in （caffe ）初始化下会发散，
		而 ELU 网络在Fan-in/Fan-out下都能收敛

	Maxout

		f(x) = max ( w1 × x + b1, w2 × x + b2, ⋯ , wn * x + bn )
		这个激活函数有点大一统的感觉，因为maxout网络能够近似任意连续函数，
		且当w2,b2,…,wn,bn为0时，退化为ReLU。Maxout能够缓解梯度消失，
		同时又规避了ReLU神经元死亡的缺点，但增加了参数和计算量。

损失函数
	平方差函数

			C = 1/2 (a−y)^2

		y是我们期望的输出向量，a为神经元的实际输出向量 a = σ( W * x + b) 使用了sigmoid激活函数
		我们知道参数修正量是
			∂C
			__ = (a−y) .* a .* (1−a) * xT
			∂W
	
			∂C
			__ = (a−y) .* a .* (1−a)
			∂b
		因为sigmoid函数的性质，导致σ′(z)在z取大部分值时会造成饱和现象，
		从而使得参数的更新速度非常慢，甚至会造成离期望值越远，更新越慢

	交叉熵函数  //(交叉熵的讨论依然存在严重问题，特别是求导，和用于logistic分类的概念)
		一般情况
		
			H(y,a) = − ∑ ( yi * ln(ai) )
				   i
	
			这里 y，a 指的是向量，y:[y1, y2,,,yi],	a:[a1,a2,,,ai]
			所以 yi，ai指的是向量中的 第i个成员
			譬如 辨别一个交通工具属于 汽车，飞机，船 三类中那一类？
				y属于期望向量：[1,0,0]表示属于飞机，[0,1,0]表示属于汽车 [0,0,1]表示属于船！！
				一台宝马算出的实际向量a: [0.05,0.8，0.15]
				表示机器学习到：宝马有 0.05概率属于飞机，0.8概率属于汽车，0.15概率属于船，
				然而实际上：宝马是 0% 概率属于飞机，100%属于汽车，0%概率属于船，
				即机器学习到对于 一台宝马这个样本来说： y：[0,1,0] a:[0.05,0.8，0.15]
					属于飞机的 期望概率分布值是 y1=0 ，实际概率分布值是 a1=0.05
					属于汽车的 期望概率分布值是 y1=1 ，实际概率分布值是 a1=0.8
					属于船的   期望概率分布值是 y1=0 ，实际概率分布值是 a1=0.15
				则 这个样本的 H(y,a) = -（ 0*ln（0.05） + 1*ln(0.8) + 0*ln(0.15) ）
				显然只有 a2（0.8) 那项有效，当a2越接近1, ln（a2）越小，H(y,a)越小，学习结果越准确
			当然 y向量的成员不一定只有0和1两值，还有其他复杂的情况例如 y:[90,7,0.56,,,],这些示情况讨论

		如果有多个样本，则整个样本的平均交叉熵为：

				   1
			H(y,a) = − _ * ∑ ∑ ( yi,n * ln(ai,n))
				   n   n i

			其中其中 yi,n 表示第n个期望样本y向量的第i个成员
			其中其中 ai,n 表示第n个实际样本a向量的第i个成员

		关于交叉熵的 logistic分类讨论，
			logistic分类 讨论的 二选一，问题：
			比如 判断一只兔子是不是人类，对于这个样本判断，期望值当然是百分100%非人类
			比如 一张中奖彩票，对于这个样本，期望值是30% 出现，70%不出现
			我们回顾之前讨论的的 logistic 分类模型！！
			
					z = hx + b	

				n维的输入列向量 x，
				有一个n维的参数横向量h，（也叫权重向量） 
				还有一个偏置量b，
				z是一个数，z的值域是 [−∞,+∞] ，是无法根据z来判断列向量 x 到底是属于0还是1的	
				引入 sigmoid函数，将z的值映射到[0,1]之间

						    1
					σ(z) =	_________	即, a = σ(z) = σ( hx + b )		
						1 + e^(-z)	

			对于一个样本 x向量，
				他 属于   某一个类别的 期望概率分布值是 y ，实际概率分布值是 a
				他 不属于 某一个类别的 期望概率分布值是 （1-y） ，实际概率分布值是 （1-a）
			所以他的交叉熵是
		
				H(y,a) = −（ y * ln(a) + (1−y) × ln(1−a)）
			
			很多时候，我们只讨论简单的 是与不是 的问题，所以 期望值y是 1和0 两者其一
				即对于某一样本例子 y是1 则 H(1,a) = -（ln（a））
				若对于又一样本例子 y是0,则 H(0,a) = -（ln（1-a））

			如果有多个样本， logistic分类 交叉熵 公式就变成

					   1
				H(y,a) = − _ × ∑ （ y * ln(a) + (1−y) × ln(1−a) ）
					   n   n

			由于，交叉熵，我们是引入作为 损失函数的，最后需要反向传导修正学习模型的参数！！
			所以接下来要讨论 参数修正量(参数的偏导数)的问题！！
			首先我们一般使用的是 多个样本logistic分类交叉熵 公式作为 logistic分类 的损失函数。
			如果我们一次有10个样本 x向量，
				即有10个： z = hx + b  向量乘法，和 10次sigmoid激活函数修改  a = σ(z) = σ( hx + b )
			那么 H(y,a) 的 n 就是10
			每个样本都有自己 y 和 a ，y和a 是实际数字  
			对于 H(y,a)， y 和 a 是参数。即有 10对不同的（y，a）代入，求出了H(y,a)
			因为带入 y 的数字是10个不一样的值，代入a的数字也是10个不一样的值，
			所以，应该 H(y,a) 有20个参数，而不是2个，其中有10个相对独立的y，和10个相对独立的a
			所以把式子变一下方便阅读

			H( y.1, y.2, ~~ y.10, a.1, a.2, ~~,a.10) 

					   1
				       = − _ ×  ∑   （ y.j * ln(a.j) + (1−y.j) × ln(1−a.j) ）
					   n   n=10
			
			注意，虽然把每个a都看作一个独立参数 a.j 但是算法公式都一样 a = σ(z) = σ( hx + b )
			即 同 一个 h向量权重 h:[h1,h2,h3,,,,,,] 和 b 偏移！！

					∂a.j   ∂a    ∂σ
			即会了例如有：	____ = ___ = ___   hi是h的某一成员	
					∂hi    ∂hi   ∂hi
			
			还有一个特别注意的 数学特性  σ′(z)=σ(z)(1−σ(z))
			那么：


			∂C     1          ∂C    ∂a.j
			___ = −_ * ∑  [  ____ * ___  ]
			∂hi    n   n     ∂a.j   ∂hi

			       1          y     (1−y)       ∂σ
			    = −_ * ∑ [ ( ____ − _____   ) * ___ ]
			       n   n     σ(z)   1−σ(z)      ∂hi

			       1          y     (1−y)       
			    = −_ * ∑ [ ( ____ − _____   ) * σ′(z) × xi ]
			       n   n     σ(z)   1−σ(z)      

			       1         σ′(z) × xi       
			    = −_ * ∑ [  _____________    * (σ(z)−y) ]
			       n   n    σ(z) * (1−σ(z))  			

			      1               
			    = _ * ∑ [ xi * ( σ(z) − y ) ]
			      n   n     




			∂C     1          ∂C    ∂a.j
			___ = −_ * ∑  [  ____ * ___  ]
			∂b     n   n     ∂a.j   ∂b

			       1          y     (1−y)       ∂σ
			    = −_ * ∑ [ ( ____ − _____   ) * __ ]
			       n   n     σ(z)   1−σ(z)      ∂b

			      1               
			    = _ * ∑ [ σ(z) − y ]
			      n   n     

			由于这两个算子都避开了 σ′(z)，因为 σ′(z)会几乎等于0，修正参数就不能传递到底层网络，出现了梯度消失现象
			交叉熵 很好绕过反向传导梯度消失的问题！！！ 
			这里之讨论了 最简单的logistic分类问题，如何拓展到logistic扩展(多样分类)，以后在讨论！！
			
		以下是对于交叉熵的错误理解！！！
			交叉熵的重点是先分辨单样本输入，和多样本输入的概念！！！ 
			单样本输入 如 z = h × x + b ，z为 结果值 h是横向量，x是样本列向量， b为偏移量
				这里 z 表示 x 属于某输出内容的概率
			多样本输入 如 z = h1 × x1 + h2 × x2 +,,,+b，
				z为 结果值 h1,h2,，分别都是横向量，x1,x2,,都是样本列向量， b为偏移量
				也可以写成：
					z = ( ∑ (wn * xn) ) + b
					      n
				这里 z 表示 x们 都属于某输出内容范畴的概率			
	
监督学习，监督学习算法是给定一组输入和输出，学习如何关联输入和输出
	上面讲的 feedfroward 分类的例子，属于监督学习












20170512			
机器学习破解验证码(cnn模型):http://blog.topspeedsnail.com/archives/10858/comment-page-1#comment-1332
		  	http://blog.csdn.net/ljp1919/article/details/64501002
			位置:/home/kingders/other/tensorflow_study/ramdom_captcha
	整个项目使用python2
	拷下来的源码开头要加上: # -*- coding:UTF-8 -*-
	python2.7 gen_captcha.py	//验证码图片生成
		出错:
		  File "/usr/lib/python2.7/dist-packages/PIL/ImageDraw.py", line 164, in arc
		    self.draw.draw_arc(xy, start, end, ink)
		TypeError: must be sequence of length 4, not 2
		解决:sudo pip2 install -U Pillow //更新pillow -u 是upgrade的意思
	python2.7 learning_and_test.py	//不断使用gen_captcha.py里的函数,生成验证码图片然后用于训练,
					//最后当正确率大于50%后输出 训练成果文件
		出错1:
		  File "learning_and_test.py", line 164, in train_crack_captcha_cnn
		    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output, labels=Y))
		TypeError: sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'
		解决,与python2.7版本有关:
		loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(output, Y)) //此版本python2.7使用这种格式
		#loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output, labels=Y))
		出错2:
		  File "learning_and_test.py", line 178, in train_crack_captcha_cnn
		    sess.run(tf.global_variables_initializer())
		AttributeError: 'module' object has no attribute 'global_variables_initializer'
		解决,与python2.7版本有关:
		#sess.run(tf.global_variables_initializer())
 		sess.run(tf.initialize_all_variables()) //此版本python2.7使用这种格式
	python2.7 test.py	//使用训练成果文件 验证验证码!!
		出错1:
		  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py", line 1087, in restore
		    if not gfile.Glob(save_path):
		  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/gfile.py", line 262, in Glob
		    return _glob.glob(glob)
		  File "/usr/lib/python2.7/glob.py", line 27, in glob
		    return list(iglob(pathname))
		  File "/usr/lib/python2.7/glob.py", line 38, in iglob
		    if not has_magic(pathname):
		  File "/usr/lib/python2.7/glob.py", line 95, in has_magic
		    return magic_check.search(s) is not None
		解决,与python2.7版本有关:
		saver.restore(sess, tf.train.latest_checkpoint('.'))	//可以这样
		#saver.restore(sess, "crack_capcha.model-7000")		//或者可以这样
		saver.restore(sess, tf.train.latest_checkpoint('crack_capcha.model-7000'))	//不可以这样
		出错2
		明明使用test.py,但是就偏偏也运行上了 learning.py 不应该运行的 train_crack_captcha_cnn()
		解决:
		给 train_crack_captcha_cnn() 前加上 if __name__ == '__main__': 
		出错3:
		各种notfound 问题,
		解决,后来发现 def crack_captcha 这个函数,还是放在 learning好,test.py只调用就好了!!1	
	总结:
		gen_captcha.py	定义了验证码生成函数 gen_captcha_text_and_image 并演示了 验证码生成
		learning.py	定义了cnn模型,
			   	定义了训练函数 train_crack_captcha_cnn
				定义了使用训练模型破解验证码的函数 crack_captcha
				并执行了训练函数 train_crack_captcha_cnn 训练结束生成训练模型 crack_capcha.model-7000
		test.py		执行了使用训练模型破解验证码的函数 crack_captcha
	通过learing 掌握 tensorboard 使用方法!!
		后台运行 tensorboard :	$ tensorboard --logdir=/tmp/logs &
					Starting TensorBoard 16 on port 6006
					(You can navigate to http://0.0.0.0:6006)
		learning.py里,我们对 accuracy 和 loss
			//定义初始化好 accuracy 和 loss 变量后,才添加监控项,即:
			//loss = tf.reduce_mean(...)
			//accuracy = tf.reduce_mean(...)
			//之后,添加监控项:
			tf.scalar_summary("loss", loss)	
			tf.scalar_summary("accuracy", accuracy)
			//把所有要监控的项 打包
			merged_summary_op = tf.merge_all_summaries()
			//初始化所有变量,sess.run(tf.initialize_all_variables())
			//动态监控文档放在 /tmp/logs文件夹里
			//注意,tf.initialize_all_variables() 是初始化了所有变量
			//sess.run()又是开始了迭代计算训练
			//初始化了所有变量,又开始了迭代计算训练才能添加动态监控文档:
			summary_writer = tf.train.SummaryWriter('/tmp/logs', graph_def=sess.graph_def)
			//注意后面的,
			//acc = sess.run(accuracy, feed_dict={X: batch_x_test, Y: batch_y_test, keep_prob: 1.})
			//_, loss_ = sess.run([optimizer, loss], feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.75})
			//都读取迭代训练中途得到的数据结果,然后根据结果,更改收敛条件后,重新继续迭代训练
			//也就说,自从第一次sess.run后,就开始了迭代训练的计算,
			//每当下一次sess.run指令之前,中间其实经历了多次迭代训练,而不是只计算1次
			//迭代计算的结果是离散的,只有不断更改收敛条件才可以优化下一段时间的迭代计算,
			//而关于tensorboard调用的sess.run,只是得到当前迭代计算得到的结果,并没有更改收敛条件来影响后面的迭代训练活动
			summary_str = sess.run(merged_summary_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.75})
			//然后,上传到监控文件
			summary_writer.add_summary(summary_str, step)
		然后浏览器输入:http://0.0.0.0:6006/
			便能看到结果,如果发现没有内容,rm -r /tmp/logs/* 		//*/清空内容
			重新打开tensorboard 试试

补充:
python的一些重要模块:
	NumPy和SciPy是开源的 Python 的科学计算模块	
		NumPy：怎么处理缺失的数字:http://blog.topspeedsnail.com/archives/866
		NumPy入门详解:http://blog.topspeedsnail.com/archives/599
	pygame
		PyGame教程一：开始:http://blog.topspeedsnail.com/archives/2155
		PyGame教程二：声音和音乐:http://blog.topspeedsnail.com/archives/2166

python的一种调用函数时的注意点:
		假如:
		a.py:	def了aa,bb,cc函数, 
			python a.py 时,会运行a.py的全局命令行, 
		b.py:	需要调用 a.py 的 aa 和 cc 函数, 就得加两行头 from a.py import aa,  from a.py import cc
			但是python b.py 时,除了成功调用aa cc外,还会,把a.py的全局命令行也执行一遍
			如果 b.py 只想运行自己的命令行,而不想执行 a.py 的命令行,但有可以使用别人def的函数,
			那么就得在 a.py的命令行前加上 if __name__ == '__main__':
			这样子: 
				python a.py 依然能完美执行自己的所有命令行
				python b.py 只执行自己的命令行,
python完美print出中文:
		print("某某某 {}, 哈哈哈 {} {} ".format(num1,charb,textc))  # (60, 160, 3)
		效果例子: 某某某 467, 哈哈哈 g kingders
		关键使用 " .format()" 格式函数  











20171219
tensorflow 常用内容(python):
Tensor的意思是张量，其实就是指矩阵。Tensor的生成方式有很多种，最简单的就如
	import tensorflow as tf # 在下面所有代码中，都去掉了这一行，默认已经导入
	a = tf.zeros(shape=[1,2])
	注意,在训练开始前，所有的数据都是抽象的概念，就是说，此时a只是表示这应该是个1*2的零矩阵，
	并没有实际赋值，也没有分配空间，所以如果此时 print(a); ,就会出现如下情况:
		#===>Tensor("zeros:0", shape=(1, 2), dtype=float32)
	只有在训练过程开始后，才能获得a的实际值
		sess = tf.InteractiveSession()
		print(sess.run(a))
		#===>[[ 0.  0.]]
Variable 变量,例如 y=Relu(Wx+b),Y = W × x + b 等在矩阵方程中, W矩阵,b向量 就属于变量
	W = tf.Variable(tf.zeros(shape=[1,2]))	//声明一个 1*2 零矩阵,把这个变成变量W,然后这个1*2 零矩阵就是W变量的初始状态,
	此时W一样是一个抽象的概念，而且与Tensor不同，Variable必须初始化以后才有具体的值:
		tensor = tf.zeros(shape=[1,2])
		variable = tf.Variable(tensor)
		sess = tf.InteractiveSession()
		# print(sess.run(variable))  # 会报错
		sess.run(tf.initialize_all_variables()) # 对variable进行初始化
		print(sess.run(variable))
		#===>[[ 0.  0.]]
placeholder占位符 用于表示输入输出数据的格式,现在没法得到具体数值
	x = tf.placeholder(tf.float32,[1, 5],name='input')	//声明x占位符号,是一个 1*5 的矩阵,即一个5维向量x
	y = tf.placeholder(tf.float32,[None, 5],name='input')	//声明y占位符号,是一个 ?*5 的矩阵,
	第一种x，表示输入是一个[1,5]的横向量。
	第二种形式，表示输入是一个[?,5]的矩阵。那么什么情况下会这么用呢?就是需要输入一批[1,5]的数据的时候。
	比如我有一批共10个数据，那我可以表示成[10,5]的矩阵。
	如果是一批5个，那就是[5,5]的矩阵。tensorflow会自动进行批处理
Session 会话。session是抽象模型的实现者。
	模型是抽象的嘛，只有实现了模型以后，才能够得到具体的值。
	同样，具体的参数训练，预测，甚至变量的实际值查询，都要用到session

例子分析:
官方 mnist数据集的分类 
	使用 feedfroward 模型:
		z=Wx+b
		a=softmax(z)
	模型建立:
		x = tf.placeholder(tf.float32, [None, 784]) # 输入占位符  x是图片数据相当于 28*28=784维向量x 
		y = tf.placeholder(tf.float32, [None, 10])  # 输出占位符  是一个10维向量y,是已知输出!!!
		W = tf.Variable(tf.zeros([784, 10]))        # 784*10 矩阵
		b = tf.Variable(tf.zeros([10]))
		a = tf.nn.softmax(tf.matmul(x, W) + b)      # z是实际输出,a是实际输出的归一化结果
		# 定义损失函数和训练方法
		cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(a), reduction_indices=[1])) # 损失函数为交叉熵
		optimizer = tf.train.GradientDescentOptimizer(0.5) # 梯度下降法，学习速率为0.5
		train = optimizer.minimize(cross_entropy)  # 训练目标：最小化损失函数
		模型中的所有元素(图结构，损失函数，下降方法和训练目标)都已经包括在train里面,所以train叫做训练模型	
	实际训练
		sess = tf.InteractiveSession()      # 建立交互式会话
		tf.initialize_all_variables().run() # 所有变量初始化
		for i in range(1000):
		    batch_xs, batch_ys = mnist.train.next_batch(100)    # 获得一批100个数据
		    train.run({x: batch_xs, y: batch_ys})   # 给训练模型提供输入和输出
		print(sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}))
		在模型搭建完以后，我们只要为模型提供输入和输出，模型就能够自己进行训练和测试了。
		中间的求导，求梯度，反向传播等等繁杂的事情，tensorflow都会帮你自动完成。
	模型检测:
		correct_prediction = tf.equal(tf.argmax(a, 1), tf.argmax(y, 1))
		accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
		就是比较 a 与 y 的相似, tf.equal把 a归一向量与 y向量 按位与操作,得到结果向量 orrect_prediction
		tf.cast将boolean数组转成int数组，最后求平均值，得到分类的准确率

20171218
分析 android tensorflow demo 项目
	该项目有三个项目目录:
		org.tensorflow
		org.tensorflow.contrib.android
		org.tensorflow.demo
		各自源码目录位置可以从 build.gradle,找到!!!
	    sourceSets {
	        main {
	            if (nativeBuildSystem == 'bazel' || nativeBuildSystem == 'makefile') {
	                // TensorFlow Java API sources.
	                java {
	                    srcDir '../../java/src/main/java'
	                    exclude '**/examples/**'			//备注掉  */
	                }
	
	                // Android TensorFlow wrappers, etc.
	                java {
	                    srcDir '../../contrib/android/java'
	                }
	            }
	            // Android demo app sources.
	            java {
	                srcDir 'src'
	            }
	
	            manifest.srcFile 'AndroidManifest.xml'
	            resources.srcDirs = ['src']
	            aidl.srcDirs = ['src']
	            renderscript.srcDirs = ['src']
	            res.srcDirs = ['res']
	            assets.srcDirs = [project.ext.ASSET_DIR]
	            jniLibs.srcDirs = ['libs']
	        }
	
	        debug.setRoot('build-types/debug')
	        release.setRoot('build-types/release')
	    }		
	









20171229
机器学习基础：
	在这里数学符号的写法表达
		向量 x 这里写作 x：[x1,x2,x3...] 
		向量 x 的转置写作 x‘T
		矩阵 A 这里写作	A: ⎡A11,A12,A13... ⎤
				    ⎢A21,A22,A23... ⎥
				    ⎢A31,A32,A33... ⎥
				    ⎣....           ⎦ 
		矩阵 A  的转置写作 A‘T
		矩阵 A  的逆矩阵写作 A‘（-1）	
		单位矩阵 In （nxn的矩阵）： A ’−1 A = In
		正交矩阵：A‘T A = A A’T = I.	A‘−1 = A’T
		对称： A‘T = A
	线性相关/无关
		一组 向量中的 任意一个 向量都不能被其他向量的线性组合表示,那么这组向量称为 线性无关
		一组 向量中的 一个或多个 向量能被其他向量的线性组合表示,那么这些向量是冗余的，被称为 线性相关
	范数 (L'p)： 类似于向量绝对值，认为是广义多维向量绝对值	
			∥x∥_p =	( ∑ |xi|^p )^(1/p)		
		例子：如果 p=2, x：{3,4} 则 范数为： (3^2 + 4^2)^(1/2) = 5 
		当 p = 2 时,L'2 范数被称为 欧几里得范数
		两个向量的 点积(dot product)可以用范数来表示：x’⊤ y = ∥x∥_2 ∥y∥_2 cosθ	
	典型矩阵范数：也叫Frobenius 范数

			∥A∥_F = √ (  ∑  (Aij)^2 ) ,
				    i,j
	A ⊙ B: A 和 B 的逐元素乘积(Hadamard 乘积)
		A =
			⎡A11,A12,A13... ⎤
			⎢A21,A22,A23... ⎥
			⎢A31,A32,A33... ⎥
			⎣....           ⎦ 
		B =
			⎡B11,B12,B13... ⎤
			⎢B21,B22,B23... ⎥
			⎢B31,B32,B33... ⎥
			⎣....           ⎦
		A ⊙ B =
			⎡A11*B11,A12*B12,A13*B13... ⎤
			⎢A21*B21,A22*B22,A23*B23... ⎥
			⎢A31*B31,A32*B32,A33*B33... ⎥
			⎣....         		    ⎦  
	对角矩阵(diagonal matrix)只在主对角线上含有非零元素,其他位置都是零。
		我们用 diag(v) 表示一个对角元素由向量 v 中元素给定的对角方阵。
		v = [2 1 -1 -2 -5];
		D = diag(v)
		D = 
		    ⎡ 2     0     0     0     0  ⎤
		    ⎢ 0     1     0     0     0  ⎥
		    ⎢ 0     0    -1     0     0  ⎥
		    ⎢ 0     0     0    -2     0  ⎥
		    ⎣ 0     0     0     0    -5  ⎦ 
		所以有： 
			diag(v) x = v ⊙ x
			diag(v)‘−1 = diag( [1/v1 , . . . , 1/vn ]’⊤  )
	如果 x‘⊤ y = 0,那么向量 x 和向量 y 互相 正交(orthogonal)	
		如果两个向量都有非零范数,那么这两个向量之间的夹角是 90 度
		如果这些向量不仅互相正交,并且范数都为 1,那么我们称它们是 标准正交
	特征分解
			A v = λ v
		v ：方阵 A 的 特征向量
		标量 λ 对应的 特征值
		左特征向量(left eigenvector)： v‘⊤ A = λ v’⊤		
		右特征向量(right eigenvector)：A v = λ v  （重点关注）
		如果 v 是 A 的特征向量,那么任何缩放后的向量 sv (s ∈ R,s ̸ = 0) 也是 A 的特征向量
		假设 矩阵A 有n个线性无关的特征向量 {v(1) , . . . , v(n) }，对应着特征值 {λ1 , . . . , λn}。
		将 特征向量 连接成一个矩阵, 使得每一列是一个特征向量:V = [v(1) , . . . , v(n)]	
		将 特征值 连接成一个向量 λ = [λ1 , . . . , λn ]‘T
		A 的 特征分解(eigendecomposition)可以记作
			A = V diag(λ) V’−1 .
		每个实对称矩阵都可以分解成实特征向量和实特征值，其中 Q 是 A 的特征向量组成的正交矩阵,Λ 是对角矩阵。
			A = Q Λ Q‘⊤
		所有特征值都是正数的矩阵被称为 正定
		所有特征值都是非负数的矩阵被称为 半正定	
		所有特征值都是负数的矩阵被称为 负定
		所有特征值都是非正数的矩阵被称为 半负定
		半正定矩阵受到关注是因为它们保证  ∀x, x’⊤ A x ≥ 0。此外,正定矩阵还保证 x‘⊤ A x = 0 ⇒ x = 0
	奇异值分解 SVD
			A = U D V’⊤
		A 是一个 m × n 的矩阵，U 是一个 m × m 的矩阵，D 是一个 m × n的矩阵，V 是一个 n × n 矩阵
		矩阵 U 和 V 都定义为正交矩阵,而矩阵 D 定义为对角矩阵。注意,矩阵 D 不一定是方阵
		对角矩阵 D 对角线上的元素被称为矩阵 A 的 奇异值(singular value)。
		矩阵U 的列向量被称为 左奇异向量(left singular vector),矩阵 V 的列向量被称 右奇异向量(right singular vector)。
		A 的 左奇异向量(left singular vector)是 A A‘⊤ 的特征向量。 
		A 的 右奇异向量(right singular vector)是 A’⊤ A 的特征向量
		A 的非零奇异值是 A ⊤ A 特征值的平方根,同时也是A A‘⊤ 特征值的平方根。
		每个实数矩阵都有一个奇异值分解,但不一定都有特征分解。例如,非方阵的矩阵没有特征分解,这时我们只能使用奇异值分解。
	Moore-Penrose 伪逆
		由来：
			假如有 A x = y，希望的到 一个 A’-1, 使得 A‘-1 A x = A’-1 y 即 x = A’-1 y
			A 不一定是方阵！！！！
			假如 A 和 y 已知道， 求 X  
			如果矩阵 A 的行数大于列数,那么上述方程可能没有解。
			如果矩阵 A 的行数小于列数,那么上述 x 可能有多个解，意味着 A’-1 也有多个！！！
		理论上我们设计了一个 Moore-Penrose 伪逆：	
			A‘+ = lim ( A’⊤ A + α I )‘−1 A’⊤	//I是单位矩阵
			      α↘0
		实际上的到 Moore-Penrose 伪逆 的计算方法是： A‘+ = V D’+ U‘⊤
		矩阵 U,D 和 V 是矩阵 A奇异值分解后得到的矩阵，
		对角矩阵 D 的伪逆 D’+ 是其非零元素取倒数之后再转置得到的
		如果矩阵 A 的行数小于列数，这个伪逆 A'+，就是上述 A’-1 其中的一个，
			而且得到的 x 是所有可行解中欧几里得范数 ∥x∥_2 最小的一个,即得到的向量x 绝对值最小
		如果矩阵 A 的行数大于列数，x 可能没有解，这时伪逆 A'+并不是上述 A’-1 其中的一个，
			当强行运算 得到的错误向量X 会有 Ax 和 y 的欧几里得距离 ∥Ax − y∥_2 最小 的特性
	迹运算：
		返回的是矩阵对角元素的和:
			Tr(A) = ∑（Aii） 
		Frobenius范数：∥A∥_F = √ ( Tr(A A'⊤) )
		Tr(A) = Tr(A'⊤)
								     n			     n-1
		Tr(ABC) = Tr(CAB) = Tr(BCA) 或者更一般地可表示为 Tr(  ∏  F'(i) ) = Tr( F'(n)   ∏  F'(i)
								    i=1			     i=1
		标量在迹运算后仍然是它自己:a = Tr(a)
		设矩阵 A ∈ R'(m×n) ,矩阵 B ∈ R'(n×m) ,
			我们可以得到Tr(AB) = Tr(BA) 
			尽管 AB ∈ R'(m×m) 和 BA ∈ R'(n×n)。
			（R'(m×n) 表示 任意mxn的实数矩阵 的意思）
	行列式：
		记作 det(A)
		例如三阶行列式：
			⎢A11,A12,A13 ⎥
			⎢A21,A22,A23 ⎥	= A11A22A33 + A12A23A31 + A13A21A32 - A13A22A31 - A12A21A33 - A11A23A32
			⎢A31,A32,A33 ⎥
		可证明：行列式等于矩阵特征值 的乘积
		行列式的绝对值可以用来衡量矩阵参与矩阵乘法后空间扩大或者缩小了多少。
		如果行列式是 0,那么空间至少沿着某一维完全收缩了,使其失去了所有的体积。
		如果行列式是 1,那么这个转换保持空间体积不变。
	deeplearnbook 的 2.12 实例:主成分分析实例 讲解，可帮助揉合使用 线性代数知识！！

	概率论基础：
		概率质量函数，明确写出随机变量x为dd的概率: P(x=dd)
		随机变量x 遵循的分布:x ∼ P (x)
		 ∑（P (x)） = 1.这条性质称之为 归一化的(normalized) ，表示所有可能发生事件的概率的和为1
		研究的对象是 连续型 随机变量时,我们用 概率密度函数 且有： ∫ p(x)dx = 1
		研究的对象是 离散型 随机变量时,我们用 概率质量函数 且有： ∑（P (x)） = 1
	边缘概率：
		定义：已知 一组 混合变量概率分布,想知其中 一个 变量子集 的概率。	
		离散型：∀x ∈ x, P (x = x) = ∑ P (x = x, y = y). 
					    y
		连续型：p(x) = ∫ p(x, y)dy
	条件概率：
		求在某条件下的 某变量子集的 概率
				    P (y = y, x = x)
		P (y = y | x = x) = ________________
					P (x = x)
		P (y = y, x = x): x和y 同时发生的概率
 		P (x = x): x发生的概率
		P (y = y | x = x): 假设x会发生情况下，y也会发生的概率
		乘法法则：
							        n
			P ( x(1) , . . . , x(n) ) = P ( x(1) )  Π  P ( x(i) | x(1) , . . . , x(i−1) )
							       i=2
			例子：
			P (a, b, c) = P (a | b, c)P (b, c)
			P (b, c) = P (b | c)P (c)
			P (a, b, c) = P (a | b, c)P (b | c)P (c).
	独立性：
		相互独立：  ∀x ∈ x, y ∈ y, p(x = x, y = y) = p(x = x)p(y = y)
		条件独立：  ∀x ∈ x, y ∈ y, z ∈ z, p(x = x, y = y | z = z) = p(x = x | z = z)p(y = y | z = z)
	期望，方差，协方差：
		已知离散型x分布x ∼ P (x)，求 f(x) 的期望： E_x∼P [f(x)] = ∑ P(x)f(x)
		已知连续型x分布x ∼ P (x)，求 f(x) 的期望： E_x∼p [f(x)] = ∫ p(x)f(x)dx.	
		E_x∼p [f(x)] 可简写为： E_x[f(x)] 也可简写为 E[f(x)]
		期望是线性的,如：E_x[α f(x) + β g(x)] = α E_x[f(x)] + β E_x[g(x)], 其中 α 和 β 不依赖于 x。
		方差：Var(f(x)) = E[ f(x) − E[f(x)] ]^2
		标准差： √ [ Var(f(x)) ]
		协方差:	Cov(f(x), g(y)) = E[ (f(x) − E[f(x)]) (g(y) − E[g(y)]) ]
			协方差的绝对值很大 -> 变量值变化很大并且它们同时距离各自的均值很远。
			协方差是正的 -> 两个变量都倾向于同时取得相对较大的值
			协方差是负的 -> 其中一个变量倾向于取得相对较大的值的同时,另一个变量倾向于取得相对较小的值
			两个变量的协方差不为零 -> 它们一定是相关的。
			两个变量如果协方差为零 -> 它们之间一定没有线性关系。
			独立性比零协方差的要求更强,独立性包含了非线性的关系，
			两个变量相互依赖但具有零协方差是可能的。
		向量的协方差：(未好好分析)
			随机向量 x ∈ R‘n 的 协方差矩阵(covariance matrix)是一个 n × n 并且满足,的矩阵，且满足
				Cov(x)_i,j = Cov(xi, xj).
			协方差矩阵的对角元是方差
				Cov(x i , x i ) = Var(x i )
	常用分布：
		Bernoulli 分布，即单个二值随机变量的分布
		Multinoulli 分布，范畴分布，即 x只能取 有限个值中的一个 的离散随机变量的分布
		高斯分布（正太分布）：			
			N (x; μ, σ^2 ) = √ (1 / (2πσ^2)) exp( -1/(2σ^2) (x − μ)^2 )
			标准正态分布(standard normal distribution),其中 μ = 0, σ = 1
		多维正态分布（推广到向量的正太分布）：
						1		   1
			N (x; μ, Σ) = √（_________________） exp( -__ (x − μ)'⊤  Σ'(-1) (x − μ) )
					   (2π)^n det(Σ)	   2

			向量μ 仍然表示分布的均值
			向量x， x ∈ R‘n
			Σ 给出了分布的协方差矩阵
			一般使用 Σ 时， 计算量大而且复杂，所以会以其他代替，例如是一个标量乘以单位阵，（这时称各向同性搞死分布）
		高斯混合分布： （未深入）
	常用函数：
		logistic sigmoid：
			σ(x) = 1 / （1 + exp(−x)）
		softplus：
			ζ(x) = log(1 + exp(x))
			softplus 函数可以用来产生正态分布的 β 和 σ 参数,因为它的范围是 (0, ∞)。
			当处理包含 sigmoid 函数的表达式时它也经常出现
		一些重要性质：
			σ(x) =	exp(x) / exp(x) + exp(0)

			dσ(x)
			____ = σ(x)(1 − σ(x))
			 dx
			
			1 − σ(x) = σ(−x)
	
			log σ(x) = −ζ(−x)

			dζ(x)
			_____ = σ(x)
			 dx

			∀x ∈ (0, 1), σ −1 (x) = log (x / (1 − x))

			∀x > 0, ζ'−1(x) = log(exp(x) − 1)

				x
			ζ(x) =  ∫  σ(y)dy
				−∞

			ζ(x) − ζ(−x) = x

			函数 σ −1 (x) 在统计学中被称为 分对数(logit)
		贝叶斯规则
			已知 P(y|x), P(x)计算 P(x|y)

			P (y) = ∑ P(y|x) P(x)
				x

				     P(x) P(y|x)
			P (x | y) = _____________
				        P(y)

	信息论：
		核心论点，大概率发生的事情几乎没有”信息“，但小概率发生的事情却有好多”信息“
		定义一个事件 x = x 的 自信息：
			I(x) = − ln（P(x)）
		I(x) 单位是奈特(nats)，一奈特是以 1/e 的概率观测到一个事件时获得的信息量。
		显然，P（x） 越小，I(x)越大，即表示 小概率发生的事件拥有更多”信息“
		香农熵(Shannon entropy)来对整个概率分布中的不确定性总量进行量化:
			H(x) = E_x∼P [I(x)] = −E_x∼P [log P (x)],
	
	kl散度：
		同一个随机变量 x 有两个单独的概率分布 P (x) 和 Q(x),KL散度(Kullback-Leibler divergence)可以衡量这两个分布的差异

						 P(x)
			D_KL(P||Q) = E_x∼P[ log ____  ] = E_x∼P [log P (x) − log Q(x)].
					         Q(x)
		
		交叉熵(cross-entropy) : H(P, Q) = H(P) + D_KL (P||Q)

			H(P, Q) = −E_x∼P log Q(x)
		当我们计算这些量时,经常会遇到 0 log 0 这个表达式,在信息论中,我们将这个表达式处理为 lim x→0 x log x = 0。
	概率论的结构化概率模型：（未深入）
	计算机的数值计算设计基础：	
		下溢：接近零的数被四舍五入为零
		上溢：大量级的数被近似为∞ 或 −∞ 时
		条件数：描述 输入的微小变化时，对应函数变化的快慢程度。很小的输入变化导致函数值迅速改变 可能是一个严重的问题，称为病态条件
		最终得到的 最小化或最大化的函数称为：目标函数(objective function)或 准则(criterion)
		优化得到 目标函数 过程中 误差函数称：代价函数(cost function)、损失函数(loss function)或 误差函数(error function)
	梯度(gradient)是相对一个向量求导的 导数:f 的导数是包含所有偏导数的向量,记为  ∇_xf(x)。
		即梯度指的是所有 函数对向量的 所有偏导数 的一个集合，是一个集合！！ 然后这个集合组成的一个向量！！
		∇_xf(x) 是一个向量！！
		梯度的第i 个元素是 f 关于 xi 的偏导数。
		在多维情况下,临界点是梯度中所有元素都为零的点，可这样表示 ∇_xf(x) = 0	
		梯度下降-最速下降：
			x′ = x − ε ∇_xf(x)
			ε 为 学习率，是一个确定步长大小的正标量
	Jacobian 矩阵：
		如果我们有一个函数: f : R’m → R‘n ,（即 m维向量经 f函数，得到n维向量）
		由此可见 f 是 一个有n个子函数 的函数向量 f：[f(x)_1, f(x)_2, ,,, f(x)_n]'T
		f 的 Jacobian 矩阵 J ∈ R‘（n×m） 定义为 J_i,j = ∂f(x)_i / ∂xj
	Hessian 矩阵：
		如果我们有一个函数: f : R’m → R ,（即 m维向量经 f函数，得到一个标量）
		注意 f 只是 一个多元函数 ，非函数向量
		f 的 Hessian 矩阵 H(f)(x) ∈ R‘（m×m） 定义为 ：
					 ∂'2
			H(f)(x)_i,j = ________ f(x)	=  ∂2f / ∂xi∂xj, 
					∂xi∂xj

			⎡ ∂2f / ∂x1∂x1,  ∂2f / ∂x1∂x2, 	... ∂2f / ∂x1∂xn⎤
			⎢ ∂2f / ∂x2∂x1,  ∂2f / ∂x2∂x2, 	... ∂2f / ∂x2∂xn⎥
			⎢ .....						⎥
			⎣ ∂2f / ∂xn∂x1,  ∂2f / ∂xn∂x2, 	... ∂2f / ∂xn∂xn⎦
		Hessian 矩阵 有以下性质：
			∂2f / ∂xi∂xj  = ∂2f / ∂xj∂xi	即 H_i,j = H_j,i
	Jacobian 矩阵 与 Hessian 矩阵 联系：
		如果我们有一个函数: f : R’m → R ,（即 m维向量经 f函数，得到一个标量）
		f 的 梯度，对应得到了 m 个 ∂f / ∂xi 偏导函数
		m 个 ∂f / ∂xi 偏导函数 组成一个函数向量 f’：[∂f / ∂x1， ∂f / ∂x2， ，，， ∂f / ∂xm]'T
		f‘ 的 Jacobian 矩阵 J ∈ R‘（m×m） 定义为 J_i,j = ∂（∂f / ∂xi） / ∂xj = ∂2f / ∂xi∂xj
		即这个 f‘ 的 Jacobian 矩阵 等价与 f的 Hessian 矩阵
	应用 Hessian 矩阵的一些重点：
		多维情况下,单个点处每个方向上的二阶导数是不同。Hessian 的条件数衡量这些二阶导数的变化范围。
		当 Hessian 的条件数很差时,梯度下降法也会表现得很差。这是因为一个方向上的导数增加得很快,而在另一个方向上增加得很慢。
		梯度下降不知道导数的这种变化,所以它不知道应该优先探索导数长期为负的方向。
		病态条件也导致很难选择合适的步长。步长必须足够小,以免冲过最小而向具有较强正曲率的方向上升。
 		使用 Hessian 矩阵的信息来指导搜索，会避免病态条件造成的不能高效率快速收敛的效果 牛顿法：
			基于一个二阶泰勒展开的近似函数：	x_0:是某向量（多维空间某一点），x是x_0旁边的点
			f(x) ≈ f(x_0) + (x − x_0)'⊤  ∇_xf(x_0) + (x − x_0)'⊤ H(f)(x_0) (x − x_0)
			计算这个近似函数，得到一个临界点（这个近似函数的梯度为0的点）：
			x∗ = x_0 − H(f)(x_0)'−1  ∇_xf(x_0)
			这个 x∗ 就是此刻最接近 f(x) 真正临界点的点！！ 
		另外一个避免病态条件的内容：
			在深度学习的背景下,限制函数满足 Lipschitz 连续(Lipschitz continuous)或其导数Lipschitz连续可以获得一些保证。
			Lipschitz 连续函数的变化速度以 Lipschitz常数(Lipschitz constant)L 为界:		
			∀x, ∀y, |f(x) − f(y)| ≤ L∥x − y∥_2
			这个属性允许我们量化我们的假设——梯度下降等算法导致的输入的微小变化将使输出只产生微小变化,
			Lipschitz 连续性也是相当弱的约束,并且深度学习中很多优化问题经过相对较小的修改后就能变得 Lipschitz 连续
	约束优化(constrained optimization):
		我们可能希望在 x 的某些集合 S 中找 f (x) 的最大值或最小值.
		注意 KKT 乘子 的方法
		优化就是谈论如何找合适的  ε

	机器学习基本 标准概念内容：
		通常机器学习任务定义为机器学习系统应该如何处理 样本(example)
		通常会将样本表示成一个向量 x ∈ R n ,其中向量的每一个元素 xi 是一个特征。例如,一张图片的特征通常是指这张图片的像素值。
		正则化：
			在机器学习中,许多策略显式地被设计来减少测试误差(可能会以增大训练误差为代价)。这些策略被统称为正则化。
			正则化一个学习函数 f (x; θ) 的模型,我们可以给代价函数添加被称为 正则化项(regularizer)的惩罚
			权重衰减： 注意书本讲解，还有树上例子是 从线性回归，使用更改了的 MSE 来讨论的
		泛化：
			机器学习的主要挑战是我们的算法必须能够在先前未观测的新输入上表现良好,而不只是在训练集上表现良好。
			在先前未观测到的输入上表现良好的能力被称为 泛化(generalization)。
			即在训练样本集上表现良好外，在测试样本集上表现良好的能力 叫泛化
		在训练集上 得到的误差 被称为 训练误差(training error)的度量误差，
		在测试集上 得到的误差 被称为 泛化误差(generalization error)(也被称为 测试误差(test error))	
		欠拟合是指模型不能在训练集上获得足够低的误差。
		过拟合是指训练误差和测试误差之间的差距太大。
		过拟合，也可以说学习的函数模型是几乎满足所有训练样本集，但是不满足测试集样本
		学习模型的 容量：其拟合各种函数的能力
			容量低的模型可能很难拟合训练集。
			容量高的模型可能会过拟合,因为记住了不适用于测试集的训练集性质。
			学习模型 的 单项幂数越高，不同幂数的函数项越多，其他函数项越多，学习模型的容量就越高！！
			根据学习模型由什么函数项，幂函数项目组成，可初步确定函数的 表示容量(representational capacity)
			但是根据一些实际条件或者额外条件的控制，学习模型实际表示能力有限最多达到一个有效容量，
				容量能力可能达不到自己本身表示容量的水平，由于有效容量受限于优化算法的能力,
			确定深度学习模型容量的问题特别困难，开始时并不知道应该用表示容量值为多少的 学习模型去训练

		非参数(non-parametric)模型的概念。
			我们探讨过参数模型,例如线性回归。参数模型学习的函数在观测到新数据前,参数向量的分量个数是有限且固定的。
			非参数模型没有这些限制。
			有时,非参数模型仅是一些不能实际实现的理论抽象(比如搜索所有可能概率分布的算法)。
			我们也可以设计一些实用的非参数模型,使它们的复杂度和训练集大小有关。这种算法的一个示例是 最近邻回归
			我们也可以将参数学习算法嵌入另一个增加参数数目的算法来创建非参数学习算法。
				例如,我们可以想象这样一个算法,外层循环调整多项式的次数,内层循环通过线性回归学习模型。
			从预先知道的真实分布 p(x, y) 预测而出现的误差被称为 贝叶斯误差(Bayes error)。
			最佳容量指的是 选择了最优表示容量值的学习模型
			最佳容量处的测试误差趋近于贝叶斯误差。训练误差一般可以低于贝叶斯误差,因为训练算法有能力记住训练集中特定的样本。
			当训练集趋向于无穷大时,任何固定容量的模型(例如指的是二次模型)的训练误差都至少增至贝叶斯误差。
		机器学习的 没有免费午餐定理(no freelunch theorem)表明：
			在所有可能的数据生成分布上平均之后,每一个分类算法在未事先观测的点上都有相同的错误率。
			换言之,在某种意义上,没有一个机器学习算法总是比其他的要好。
			我们能够设想的最先进的算法和简单地将所有点归为同一类的简单算法有着相同的平均性能(在所有可能的任务上)。
			这些结论仅在我们考虑所有可能的数据生成分布时才成立
			这意味着机器学习研究的目标不是找一个通用学习算法或是绝对最好的学习算法。
			暗示我们必须在特定任务上设计性能良好的机器学习算法
		超参数：
			超参数的值不是通过学习算法本身学习出来的，一般是一个用户给出的固定值
			例如，多项式的次数,作为容量超参数。控制权重衰减程度的 λ 是另一个超参数。
			用于学习参数的数据子集通常仍被称为 训练集。
			用于挑选超参数的数据子集被称为 验证集(validation set)。
			通常,80% 的训练数据用于训练,20% 用于验证
		估计和估计偏差：
			估计量是训练样本得到的 指定模型参数实际值
			均值 和 期望 是有区别的： 
			每个服从某分布的模型：
			期望：模型拥有一些有固定值的模型参数，任一个模型参数的固定值，都是这个参数在这个模型下的期望值！
			      当样本足够大，从样本计算得到的某模型参数的实际值，应该无限靠近或等于期望值
			      对于一些情况，期望表现为广义平均值的意思： u = Ex～p（y）=  ∑ [y（x）* p(x)]
			均值，在这里的意义偏向于 模型参数，有限个样本的得到的一个某内容的平均值，与期望值的意义完全不一样，
			估计的偏差表示为： 
				（实际参数）估计量计算到的期望：E(实际参数)  与  要比对的已知模型参数值（期望值），经过比对得到偏差
				      _	        _
				bias( θm ) = E( θm ) − θ
				
			例如某模型，
				我们多个样本集，
				这里我们讨论的模型参数 是 u，
				模型的 u 的期望值 是已知的 为 u1，
				每个样本集 都计算出自己的 u，从每个样本集得到 实际u值 在这里是估计量
				从所有 样本集的 实际u值 算出 实际 u值的期望 u2.
				如果，所有样本足够多，且都服从这个模型，则这个算出的期望 u2 应该 与 已知的模型 u值期望值u1 相同
				如果不相同，表示样本服从的是另一个模型，这两个模型的 u参数（期望值） 之间有偏差！！
		方差和标准差：
			注意，这里上述的偏差，和这里的方差，还有标准差 是处于同一层意义的， 
			他们与期望不是同一层的意义！！
			期望：直接指模型 A参数的系统值，
			偏差：样本表现出来的实际模型与已知模型不一样，则样本表现出来A参数的系统值 与 已知模型A参数的系统值 有偏差
			方差和标准差: 可以描述 从样本表现出来的A参数的系统值 的主要分布范围，
				    （即描述 样本表现出来的A参数的系统值 的变化程度）
			方差：Var( θ.)	样本表现出来的 θ.参数的方差
			标准差：SE( μm ) = √ [Var( μm )] 样本表现出来的 μm 参数的 标准差
			例如 通过 标准差，我们得到一个 样本表现出来的 μm 参数的 分布的置信区间，
				（是以 样本表现出来A参数的系统值 为中心的 95% 置信区间）
				(μm − 1.96SE( μm ), μm + 1.96SE( μm ))
		容易混淆的内容：以高斯分布（正太分布）为例子！！
			
						   1			( x‘（i）- μ )^2
			p( x‘（i） ; μ, σ ) = ___________ * exp( -1/2 * _________________ )
					     √( 2π * σ^2)                      σ^2
			
			某个样本 x‘（i） 服从上述正太分布模型， 
			μ 是这个 正太分布模型 的平均值， 即足够多的样本的 平均值等于 μ，即 这些样本的期望值等于 μ
			σ^2 是这个 正太分布模型 的方差， 描述了样本符合这模型时，分布的范围区间情况！！！
		
			此刻，我们有多组样本集，知道符合正太分布，未知道符合的是不是上述的真太分布

			1,
			先求出每一组样本集的样本均值，再从所有样本均值求出 一个样本均值 的期望 μ1，
			（其实就是求出 样本均值 的均值，也相当于求出所有样本的均值）
			如果 μ1 等于 μ ，就说我们这些样本都符合上述的 正太分布 某些特征
			如果不同，那真实样本 与上述模型 在 μ值 这个参数上有 偏差 bias( μ1 ) = E( μ1 ) − μ

			2,
			继续求出每一组样本集的方差，再从所有方差求出 一个方差 的期望 （σ1）^2，
			如果 （σ1）^2 等于 σ^2 ，就说我们这些样本都符合上述的 正太分布 某些特征
			如果不同，那真实样本 与上述模型 在 σ^2值 这个参数上有 偏差 bias( （σ1）^2 ) = E( （σ1）^2 ) − σ^2	

			3,
			我们知道 我们遇到的这堆真实样本 样本的均值为 μ1，（即样本均值 的期望）
			但从样本集中重新随机取出 m 个样本，得到的样本均值 μm 不一定等于 μ1，但一定是以μ1为中心的一个范围
			我们需要知道这个范围，所以求 （样本均值的期望）的方差 ！
	`			SE( μ1 )
			然后知道，我们遇到的这堆真实样本表现出来的 μ值的范围，
			是以 μ1为中心的一个范围，不一定就是μ1，这个范围为
				(μ1 − 1.96SE( μ1 ), μ1 + 1.96SE( μ1 ))  （通常取 95% 置信区间）
			即从样本集中重新随机取出 m 个样本，得到的样本均值 μm 值一般在以上范围

			4,
			我们知道 我们遇到的这堆真实样本方差为 （σ1）^2
			但从样本集中重新随机取出 m 个样本，得到的样本均值 （σm）^2 不一定等于 （σ1）^2，但一定是以（σ1）^2为中心的一个范围
			我们需要知道这个范围，所以求 （样本方差）的方差 ！
	`			SE( （σ1）^2 )
			然后知道，我们遇到的这堆真实样本表现出来的 σ^2值的范围，
			是以 （σ1）^2为中心的一个范围，不一定就是（σ1）^2，这个范围为
				(（σ1）^2 − 1.96SE( （σ1）^2 ), （σ1）^2 + 1.96SE( （σ1）^2 ))  （通常取 95% 置信区间）
			即从样本集中重新随机取出 m 个样本，得到的样本均值 （σm）^2 值一般在以上范围

	
			从这个事例中，好好搞清楚方差 期望 偏差等等的关系，
			特别是 样本方差的方差 样本均值的期望的方差 中各个指代内容！！
	均方误差(mean squared error,MSE)
		MSE = E[( θ' − θ)^2 ]
		    = [Bias( θ')]^2 + Var( θ'm )
		这个误差也可以叫交叉熵，是经验分布和高斯模型之间的交叉熵。
		偏差和方差的关系和机器学习容量、欠拟合和过拟合的概念紧密相联。
		用 MSE 度量泛化误差(偏差和方差对于泛化误差都是有意义的)时,增加容量会增加方差,降低偏差。
	最大似然估计：（思维错了！！）
		有一模型，并不知道模型的具体参数，但是抽取了m个都符合这个模型的样本 的得到一个样本集 X
		单个样本出现的概率是P(xi)，那个连续取出m个样本得到的 此刻这个样本集 的概率是 P（x1,x2,，xm）= P（X）
					  m
			P（x1,x2,，xm）=  ∏  P(xi) = P(x1)*P(x2)*..*P(xm)
					 x=1
		这时 x1,x2,，xm 已知， 模型的固定参数（例如 θ）未知 
		求出一个最优 θ，使得此时的 P（x1,x2,，xm）得到最大值，
		此刻的P（x1,x2,，xm）是关于 θ 的 函数，记作 P（x1,x2,，xm;θ）或 P(X;θ)
		此刻的P(xi)，也是关于 θ 的 函数，记作 P(xi;θ)

		求θ最优值是使得 P(X;θ) 最大值，这个便是最大似然估计公式：
						  	        m
			θ’ =argmax  P（x1,x2,，xm;θ） = argmax  ∏  P(xi;θ) = argmax P(x1;θ)*P(x2;θ)*..*P(xm;θ)
			      θ			           θ   x=1		  θ
		式子表示 θ是值 θ’ 时， P（x1,x2,，xm;θ）此刻是最大值，
		 P（x1,x2,，xm;θ）最大时，∂P（x1,x2,，xm;θ）/ ∂θ = 0，从而得到 θ
		这个算出参数 θ 一般不等于模型的本身参数θ，但是绝大部分都靠近甚至无限接近本身参数
		这种估算出 模型参数的方法就是 最大似然估计
		为什么要求取最优θ 使得 P（x1,x2,，xm）最大？这个数学意义还没有参透！！
		数学意义就是:
			此刻抽出的样本集，我们要选出一个参数θ值，使得此刻的样本集看起来是最可能出现的
			即既然这个样本集出现了，他应该有比较大的出现概率，当θ值取到一个最优值时，使得这个样品集的出现概率最好
			需要注意的是：
				θ值取到一个最优值时，使得这个样品集的出现概率最好，
				并不意味着这个样品集出现的概率 是 所有样平集出现的概率之中 最高
				我们假设这样品集出现了，那就应该有比较高的概率，
				我们是假设θ值如何取时，能得到这个尽可能是比较高的概率中最高最好的那个概率值
		还有一个性质，当样本集的数据量非常大时，最大似然估计出来的参数向真正的参数值收敛，但未知如何解释，
			暂时只能从下面二项分布模型 例子感受
		注意避免一个错误思维： 
			P（x1,x2,，xm）最大值的意思 并不是假设认为此刻得到的样本集 P（x1,x2,，xm）在所有样本集之中出现率是最高的！！
			以下的 二项分布模型 例子， 假如 出现正面 1 的概率是 0.2，出现反面 0 的概率是 0.8
			摘十次， 明明每一次都是 0 时这个10次样本集出现的 概率是最高的 = 0.7^(10)
			但 最大似然估计指的 P（x1,x2,，xm）最大值 并不是假设此刻样品集的出现概率是 所有样本集出现率之中的最大值！！ 

		从 二项分布模型 例子：讨论最大似然估计
			一个广义硬币抛出，出现正面 1 的概率是 μ，出现反面 0 的概率是 1-μ，
			每摘一次的概率分布为  P(xi;μ) = μ^(xi) * (1-μ)^(1-xi)
			连续摘十次得到这个结果集：0，0，0，1，0，0，0，1，0，0
			假设这个结果集是最大概率出现的结果集，
			那么 代入最大似然估计：
								        m
				μ‘ = argmax  P（x1,x2,，xm;μ）= argmax  ∏  P(xi;θ) = argmax P(x1;θ)*P(x2;θ)*..*P(xm;θ)
					μ		          μ    x=1	       μ			
					     m
				   = argmax  ∏  [ μ^(xi) * (1-μ)^(1-xi) ]
				       μ    x=1				
			
			由于 P（x1,x2,，xm;μ） 此刻最大，所以  ∂P（x1,x2,，xm;μ）/ ∂μ = 0
			这样就反算出 μ 得到值为 μ‘
			      m
			由于  ∏  [ μ^(xi) * (1-μ)^(1-xi) ]   连乘比较难计算，所以把式子转成以下形式
			     x=1			
			  m
			  ∑  log[ μ^(xi) * (1-μ)^(1-xi) ]   虽然结果不等于以上式子，但是意义是一样的，求导的结果没有变，而连加比较好算
		  	 x=1
			        m		       m
			即	∑  log[ P(xi;θ) ]  与  ∏  [ P(xi;θ) ] 意义一样
		  	       x=1		      x=1

				  m		
			求导： ∂{ ∑ log[μ^(xi) * (1-μ)^(1-xi)] } / ∂μ = 0
				 x=1
				  m                 m
			     =    ∑ xi - 1/（1-μ）× ∑（1-xi） = 0
				 x=1               x=1
			得到  μ = 0.2，即 μ‘值为0.2 ，就是最大似然估计出来的 μ
			即 μ = 0.2时，保证 P（x1,x2,，xm;μ） 此刻最大
			虽然实际上的 μ 不一定就是 0.2, 但是，如果样品集足够多样品，算出的 μ 就越靠近实际上的 μ。
			假如实际 μ 等于0.3, 现在有1000个样品的样品集，里面就有接近30%是1（比如28%是1,72%是0）
			根据最大似然估算出来的 μ 等于0.28，这就很靠近 0.3了
	
		根据单个数据集的得到的 最大似然估计参数 不一定很好靠近实际参数值
			这时，取多个数据集，求多个最大似然估计参数，然后取这堆估计参数的期望（均值）可能就很好靠近实际参数值了！	
		KL 散度	
			最大似然估计的参数，与 实际参数的误差，可以描述样本集的体现的模型与实际模型的差距：这个差距称 KL 散度

				D_KL( p_data ∥ p_model ) = Ex∼ p_data [log p_data(x) − log p_model(x)]

			p_data : 实际模型
			p_model：通过样本集 最大似然估计得到参数们 组成的估计模型
			即 y = [log p_data(x) − log p_model(x)] 关于样本x 服从 p_model 分布的期望！！
			D_KL(..) 最小值时，差距也就最小，实际上就是最小化这项：
				- Ex∼ p_data [log p_model(x)]
			D_KL(..)最小值为0,
			则 - Ex∼ p_data [log p_model(x)]最小值是负数 且绝对值等于 Ex∼ p_data [log p_data(x)]
			注意：（以下内容比较没说服力，因为没考证）
			p_model(x) 相当于上述讨论的 P(xi;θ) 即 ∑ log[ p_model(x) ] = ∑ log[ P(xi;θ) ] 		
			最小化 - Ex∼ p_data [log p_model(x)] 与 最大化 ∑ log[ p_model(x) ] 意义是一样的
			即最小化 kl散度，求最大似然估计 的数学意义是一样的
			都是 ∂{ ∑ p_model(x) } / ∂θ = 0
			即最优 θ 在最大化似然或是最小化 KL 散度时是相同的

	条件使然与均方差MSE关系：
		最大似然估计很容易扩展到估计条件概率 P (y | x; θ)	
			  	    m
			θ’ =argmax  ∏  P( yi | xi ;θ)
			      θ			     		
		由于连乘不好算，同样可以转成加的方式，准换后的这个这个叫 条件对数似然估计
			  	    m
			θ’ =argmax  ∑  log [P( yi | xi ;θ)]		//注意这里 log 即 ln
			      θ	   i=1

		回到 线性回归模型， 我们也可以这样理解，已知一组样本（xi，yi），
		在某xi已知的条件下，对应yi可能出现的概率，而我们要求这个yi的出现概率非常大，
		这时的yi出现概率 一般符合正太分布：p(yi | xi) = N (yi ; yi'( xi ; w), σ2 )
		yi'( xi ; w) 描述这个 yi 出现的均值（期望），
		σ2描述这个yi出现的主要分布范围，在这里直接取一个固定常数 不分析
		我们希望得到一个拟合模型 拟合这个线性回归的样本。
		也就说我们希望这个yi的分布中  yi'( xi ; w) 比较靠进 yi， 
		这个分布与 参数 w 有关，所以 p(yi | xi) = p(yi | xi ;w) = N (yi ; yi'( xi ; w), σ2 )
		运用似然的思维方式，面对此刻的样本集，参数w应该取一个最优值使得 ∏ p(yi | xi) 最大，
		即使得这个样本集的 yi集概率部分最有可能出现。
			  	    m
			w’ =argmax  ∏  P( yi | xi ;W)
			      w			
		注意，每个 P( yi | xi ;W) 都是以各自的xi为已知条件的yi分布，所以各个yi分布之间没有相干，但是都共用 参数w
		由于连乘的困难，转成连加形式，即转使用 条件对数似然，：	
			  	    m
			w’ =argmax  ∑  log [P( yi | xi ;w)]
			      w	   i=1
		根据似然思维，要使  ∑  P( yi | xi ;w) 最大， （P( yi | xi ;w)是关于条件xi的正太分布）即求以下最大：

			  m
			  ∑ log [P( yi | xi ;w)]
			 i=1
					     m   || yi’ - yi ||^2
			= −mlogσ − log(2π) - ∑   ________________
					    i=1        2σ^2

		那么以上式子对 参数w 求导等于0 得到最优参数w
		返回讨论 希望这个yi的分布中  yi'( xi ; w) 比较靠进 yi 的问题上，
		得到最优 参数w 普遍 P( yi | xi ;w)都得到经可能大的值， 那么表示 yi比较靠近真太分布的均值 yi'( xi ; w)
		从而达到 希望这个yi的分布中  yi'( xi ; w) 比较靠进 yi 的目的！！

		对比 线性回归模型 使用 均方误差的方法，我们要求， 
				   m
			MSE = 1/m  ∑  || yi’ - yi ||^2  
			          i=1
		取得最小值，同样以上式子对 参数w 求导等于0 得到最优参数w
		分析这两条式，发现对参数w求导的内容结果都是一样的！！
		验证了 MSE 可以用于最大似然估计

	权重衰减：（有必要独立讨论一下）
		先回到 线性回归 模型例子，然后我们不使用 均方差代价函数 来得到最优回归函数模型的 w标量或向量，
		而是使用 权重衰减与均方差的和 的一个代价函数： 
			J(w) = MSE train + λ (w’⊤ * w),
		λ 是提前挑选的值，控制我们偏好小范数权重的程度。
		当 λ = 0,我们没有任何偏好。
		越大的 λ ，便偏好范数越小的权重。
		最小化 J(w) 可以看作是拟合训练数据和偏好小权重范数之间的权衡。
		这会使得解决方案的斜率较小,或是将权重放在较少的特征上。
		举例说明：一个样本集，建立线性回归模型，
			训练表示容量为 2次幂函数的函数模型，使用均方差优化，表现良好，
			训练表示容量为 1次幂函数的函数模型，使用均方差优化，表现欠拟合，
			训练表示容量为 9次幂函数的函数模型，使用均方差优化，表现过拟合，
			训练表示容量为 9次幂函数的函数模型，使用权重衰减与均方差的和 优化，根据不同λ，可以表现良好/欠拟合/过拟合
		正则化一个学习函数 f (x; w) 的模型,我们可以给代价函数添加被称为 正则化项(regularizer)的惩罚。
		在权重衰减的例子中,正则化项是 Ω(w) = w‘⊤ * w。
		在我们权重衰减的示例中,通过在最小化的目标中额外增加一项,我们明确地表示了偏好权重较小的线性函数。
		有很多其他方法隐式或显式地表示对不同解的偏好。总而言之,这些不同的方法都被称为 正则化(regularization)。
		正则化是指我们修改学习算法,使其降低泛化误差而非训练误差。
		正则化是机器学习领域的中心问题之一,只有优化能够与其重要性相媲。

	贝叶斯统计：
		贝叶斯公式：
			 	   P（B|A）P（A）
			P（A|B） = _____________
					P(B)
		P(A|B)是已知B發生后A的條件概率，也由于得自B的取值而被稱作A的后驗概率。
		P(A)是A的先驗概率（或边缘概率）。之所以稱為"先驗"是因為它不考慮任何B方面的因素。
		P(B|A)是已知A發生后B的條件概率，也由于得自A的取值而被稱作B的后驗概率。
		P(B)是B的先驗概率或邊緣概率。
		证明，由于：
		P（B|A） = P(A∩B)/P(A), P（A|B） = P(A∩B)/P(B), 所以 P（B|A）P(A) = P（A|B）P(B)  
		
		贝叶斯推广公式

				   P(A)P(B|A)P(C|A,B)
			P(A|B,C) = __________________
					P(B)P(C|B)
			

		通俗例子理解：
		P(雨)：每天下雨的概率是 10%
		P(云|雨)：每个下雨天的早上会多云的概率 60%
		p(云)：每天早上多云的概率是 30%
		P(雨|云)：每天早上多云时，会下雨的概率：P(云|雨)*P(雨)/p(云)= 20%
		看起来 每天早上多云时，会下雨的概率，跟其他已知事件发生概率没有联系，但是就是可以通过贝叶斯算出来！！

		贝叶斯 处理线性回归模型：
		知道 m 个样本组成样本集(X, Y)，希望得到一个最优参数 w（这里讨论的的W是向量参数） 得到合适 y = wx 拟合样本数据，
		X是 多个样本里的 xi 向量组成的矩阵， Y 是多个样本里的 xi 标量组成的向量
		应用 贝叶斯思维来处理，
			
			首先：  p(Y | X，w) = N (Y ; X*w, σ2 )
			与条件似然讨论的 p(Y | X ;w) 意义上有区别！！！
			p(Y | X，w)： X 和 Y 都作为条件，也可以说是已发生的情况下，在p(Y | X，w)里面是常数值！！
			p(yi | xi ;w)： xi作为条件，w可以看成是一个附属条件！！但是有不影响的意思，即 p(yi | xi ;w)=p(yi | xi)
			
			然后： p(w) = N (w; μ0 , Λ0 ) ∝ exp( -1/2 （w − μ0)‘T  Λ0’（-1） (w − μ0 ) ） ,
			∝是正比于的意思。
			p(w) 是先验分布，我们假设也已知道 参数 w符合以上一般的正太分布
			这个先验分布，是我们按一般经验认为的，并不是从那里真正知道。
			μ0 和 Λ0 分别是先验分布的均值向量和协方差矩阵。

			然后我们确认后验分布： p(w | X, Y)
			这个分布如字面意思是，知道了X Y 求此刻的 w 分布概率
			使用贝叶斯推广公式：
						p(Y | w，X) * p(w) * P(X|w)
				p(w | X, Y) = _____________________________
							P(X) * P(Y|X)
		
			简化，最后发现 
			p(w | X, Y)
			∝ p(Y | X, w)p(w)					      
			∝ exp [ −1/2 （−2(Y‘⊤)Xw + (w'⊤)(X'⊤)Xw + (w'⊤) (Λ0'(-1))w − (2μ0'T) (Λ0'(-1))w ) ]
			我们定义 Λm = [ (X'⊤)X + (Λ0'(−1)) ]'(-1) 和 μm = Λm [ (X'⊤)Y + Λ0'(−1)μ0 ] 代入得
			最终简化成：
			p(w | X, Y) ∝ exp [ −1/2 ((w − μm)'⊤) (Λm'(−1)) (w − μm) ]
			即 p(w | X, Y) 简化成 N (w ; μm, 1 ) 的正太分布。
			p(w)先验分布的 Λ0 和 μ0 都是用户自己按经验取常数值的，根据取值不一样，会影响到最终参数w的最优值取值
		
		最大后验 (MAP) 估计			
				θMAP = argmax p(θ | X) = argmax log p(X | θ) + log p(θ)
					 θ		   θ
			X是一组样本集，而不是一个样本
			这里与最大似然的理解不一样，这里是知道了参数的θ 的分布，参数θ最有可能出现的值，就是最符合线性回归模型的值
			那自然也是 参数θ导数为0的地方！
			贝叶斯思维处理的线性模型 p(w | X, Y) ∝ exp [ −1/2 ((w − μm)'⊤) (Λm'(−1)) (w − μm) ]
			那么，最大后验估计求优值，就是求exp [ −1/2 ((w − μm)'⊤) (Λm'(−1)) (w − μm) ]对w导数等于0的地方

	支持向量机(SVM)
		这个概念的理解，先暂时抛弃以上 似然估计，贝叶斯统计，线性回归模型的概念，是全新内容！！
		书上写得相当垃圾，只给了些泛泛之词的理论，无法学习理解，只能各种搜资料。
		参考 ：https://www.zhihu.com/question/21094489
		还有下下来的 数据挖据十大算法书



		x2                                       /
                 |                                      /
                 |                              A      /
                 |               A                    /         B
                 |                                   /                    B
                 |                  A               /          B
                 |          A                      /   B
                 |                A               /           B     B
                 |                          A    /
                 |                              /
                 |               A         A   /         B
                 |                            /
                 |                           /                    B
                 |                          /
                 |                         /               B
                 |                        /
                 |_______________________/__________________________________________x1
                                        /
                                       /

		如图，一个平面上按区域规律散放着一些苹果（A） 和香蕉（B）
		如何划分这两个散放的 不同区域？
		首先，每个物件的 平面坐标是一个x向量 （x1,x2），
		找出 一条例如上图所示的直线 划分两个区域，这条直线的式子：
			wx+b = 0
			w是一向量参数
			原点到直线的垂直最近距离为 |b| / ||w||
		这时就会发现，
			如果是 苹果 的坐标 代入 wx+b > 0 = k
			这个苹果到直线的垂直最近距离为 k / ||w||
			如果是 香蕉 的坐标 代入 wx+b < 0 = n
			这个苹果到直线的垂直最近距离为 |n| / ||w||
		然而如何取得这个合适的分隔直线：
			基本想法是，所有点都应该尽可能远离这条分隔直线
			假设 1 表示是苹果，-1 表示是香蕉，那个每个苹果样本是（x1，x2，y=1），每个香蕉样本是（x1，x2，y=(-1)）
			还有习惯上，我们设最近分隔直线的苹果处于 wx+b=1 的直线上，最近分隔直线的香蕉处于 wx+b=（-1） 的直线上，
			那么这个香蕉和苹果的垂直分隔直线的距离为  2 / ||w||
			而对于每一个样本不论是苹果或者香蕉 都满足 y*（wx+b）>= 1
			最大化 2 / ||w|| 这个距离， 就相当于所有点尽可能远离这条分隔直线，相当于最小化 ||w|| .
			由于||w||是一个单调函数,变成 ||w||^2 后，也是一个单调函数，最小化 ||w||与最小化||w||^2意义相当
			所以，为了方便后续计算，最小化 ||w|| 我们变成最小化  1/2 * ||w||^2

			最后问题转变成 	1/2 * ||w||^2 最小且， 每一个样本满足  y*（wx+b）>= 1	
				即：  min  [ 1/2 * ||w||^2 ] 
				     s.t   y(i) *（w x(i) + b）>= 1,i=1,2,...n
				也可以表示为：
				     max  1 / ||w||
				     s.t   y(i) *（w x(i) + b）>= 1,i=1,2,...n				
				问题解决 涉及拉格朗日对偶问题 （未完搁置，还有核函数）





		核函数：
			上述问题最多处理的是 线性问题，例如 用根直线分开两个区域
			但是如果是 非线性问题，例如，苹果在圆形区域里，香蕉在圆形区域外，分割区域的线就是一个圆
			这时我们可以通过 核函数把平面区域问题转化高一唯的3维空间 线性问题，
			再用一个分割平面分割两个空间区域，最后分割平面透过核函数 的映射，得到 原来平面问题上的分割圆！！
			线性与非线性的区别： （线性输入与输出成正比，非线性输入与输出比正比）
				线性拥有的规律： f(a+b) = f(a)+f(b), af(x) =f(ax), af(b)+cf(d) = f(ab+cd)

		k-最近邻
		
		one-hot 编码
		
		决策树
			決策樹演算法，例如ID3、C4.5或CART…等等
	
		PCA 算法

		奇异值分解 (SVD)




	注意书本举例的 线性回归(linear regression) 与之前讨论的 logistic分类，很有区别的，尽管用到的数学知识相同
		线性回归(linear regression)：
			直接把样本集的所有样本都代入均方误差公式（MSE），直接求出均方差的最小值，来得到最有 权重h（w）偏移b
			直接从理论上一气呵成讲解如何 得到最优的线性回归学习模型
		logistic分类：
、			这里的 是一个个样本分别代入 迭代计算，然后优化学习模型
			即每代入一次模型计算，随后也会执行一次优化模型的操作，
			并不像线性回归模型那样，一下子代入所有的样本到一个公式里，再从偏导数的到模型的最优参数 权重h（w）偏移b
	频率派统计：
		以上讨论的都是频率派统计，即讨论一个样本在莫个模型里的出现概率，样本之间是相对独立的
	
	流形：
		最基本的概念的连接一起的区域
		它的理解 例如是这样的：
			一个 梨状几何体，上面每一个无限细分的曲面区域可看作是一个二维平面，这个区域是这个梨状几何体的流形
			一条闭合的 “8”字曲线，上面部分无限细分的区域可看做一个一维的点，而在十字交叉处不管无限细分都是一个十字状的二维区域
			而这两种不同性质的区域都是 这条“8”字曲线的流形
	
	隐藏单元： 
		深度网络中，层（输入层/第X隐藏层）输出的内容，且作为下一层的输入内容，这些内容不可见，所以称隐藏单元	
		一般指层输出的内容，且还要经过激活函数处理后的内容才作为 隐藏单元，这层的输出单元，下层的输入单元。

	反向传播仅指用于计算梯度的方法,而另一种算法,例如随机梯度下降

	正切传播

	流形正切分类器

	优化问题:寻找神经网络上的一组参数 θ,它能显著地降低代价函数 J(θ),该代价函数通常包括整个训练集上的性能评估和额外的正则化项。

	线性分类器
		
	使用整个训练集的优化算法被称为 批量(batch)或 确定性(deterministic)梯度算法

	每次只使用单个样本的优化算法有时被称为 随机(stochastic)或者 在线(on-line)算法

	随机梯度下降(SGD)：计算当前 代价函数的梯度（导数），然后把此刻的参数值减此刻的梯度

	动量：改进的随机梯度下降(SGD)

	例如使用 Dropout的训练,通常来说,最好还是初始化每个单元使其和其他单元计算不同的函数。
		这或许有助于确保没有输入模式丢失在前向传播的零空间中,没有梯度模式丢失在反向传播的零空间中

	目前,最流行并且使用很高的 （一阶方法）优化算法包括 SGD、具动量的 SGD、RMSProp、具动量的 RMSProp、AdaDelta 和 Adam。
		所谓优化算法就是 迭代优化模型参数的操作，
		之前提到的 线性回归(linear regression) 和 logistic分类 用的并不是这些讨论的优化算法

	（二阶方法）优化算法： 牛顿法 
		
	卷积运算通过三个重要的思想来帮助改进机器学习系统: 
		稀疏交互(sparseinteractions)、 参数共享(parameter sharing)、 等变表示(equivariant representa- 	tions)。

	卷积和池化过程，但是卷积过程和池化过程的意义是不一样的，
		之前分析的卷积例子，把卷积和池化说到一块去了，是不对的，
		之前分析的卷积例子，只有卷积过程，没有池化过程
		卷积的功能是提取特征：单个核的卷积只能提取一种类型的特征
		池化输出的是邻近区域的概括统计量，一般是矩形区域。池化有最大池化、平均池化、滑动平均池化、L2范数池化等。
		池化能使特征获得平移不变性。如果我们只关心某些特征是否存在而不是在哪里时，平移不变性就很有用了。
		卷积也会产生平移不变性，注意区分，卷积对输入平移是不变的，池化对特征平移是不变的。 

	一个中间方法是学习特征,但是使用那种不需要在每个梯度计算步骤中都进行完整的前向和反向传播的方法。
		与多层感知机一样,我们使用贪心逐层预训练,单独训练第一层,然后一次性地从第一层提取所有特征,
		之后用那些特征单独训练第二层,以此类推。

	Dropout 也是一个很容易实现,且兼容很多模型和训练算法的出色正则化项

	k-means聚类算法：
		一堆样本， 先随意取 k个样本 作为k个分类的 标志，
		然后 其他样本 分别与这k个标志样本算出”距离“，最后站队到距离最近的那一类
		分类好所有样本后，每一类中的靠近这一类均值的 那个样本作为新的类标志，重新得到k个类标志
		其他样本从原有的站队剥离，按照第二步重新站队
	 	一次类推，多次迭代后，最后会收敛，得到一个很好的k种分类的分类结果

	Apriori算法：
		主要是寻找最常同时出现数据组合
		假设一数据库D有 以下数据：
			表单名	数据
			 k20	A,C,D		
			 t80	B,C,E
			 l90	A,B,C,E
			 p22	B,E
		扫面 D 得到 一维支持度计数
			A	2
			B	3
			C	3
			D	1
			E	3
		去除最小支持度的项
			A	2
			B	3
			C	3
			E	3
		据此构建 2维支持度计数，并扫描 D 计数
			AB	1
			AC	2
			AE	1
			BC	2
			BE	3
			CE	2	
		去除最小支持度的项
			AC	2
			BC	2
			BE	3
			CE	2
		据此构建 2维支持度计数，并扫描 D 计数
			ABC	1
			BCE	2
		去除最小支持度的项
			BCE	2
		最终得到最常同时出现数据组，及在数据库里的同事出现次数
	
	EM算法：即最大似然估计	

	Adaboost算法 分类器算法：
		人为设置多个弱分类，最终最终通过权重分配得到一个 结果较好的分类算法
		实例：
		有以下样本实例，样本只属于 + - 两值分类
		|           +
		|                      -
		|       +      +
		|      -
		|+          -
		|
		| +             	     -
		|   -
		--------------------------------
		有十个样本，开始时每个样本是权值是0.1
		第一次分类 h1
		    |
		|   |        +
		|   |                   -
		|   |    +      +
		|   |   -
		|+  |        -
		|   |
		| + |            	 -
		|   |-
		---------------------------
		    |
		左边是+类 ，右边是-类，单显然 右边有3个非 - 类的 +样本。
		这次弱分类的权值误差： e1 = （0.1+0.1+0.1）/1=0.3
		这次分类权重：a1 = 1/2*ln（1-e1/e1）=1/2*ln(1-0.3/0.3)=0.42
		这时被正确分类的点权值不变为0.1, 其他三个错误点权值为：D1=D0*(1-e1)/e1=0.1*(1-0.3)/0.3=0.2333

		第二次分类 h2		
		|           +       | 
		|                   |   -
		|       +      +    |
		|      -            |
		|+          -       |
		|                   |
		| +                 |    -
		|   -               |
		--------------------------------
		                    |
		左边是+类 ，右边是-类，显然 左边有3个非 + 类的 -样本。
		第一次分类后，样本集的权值和为 0.1*7 + 0.2333*3 = 1.3999
		这次弱分类的权值误差： e1 = （0.1+0.1+0.1）/1.3999=0.2144
		这次分类权重：a1 = 1/2*ln（1-e1/e1）=1/2*ln(1-0.2144/0.2144)=0.6493
		这时被正确分类的点权值不变,三个错误点权值更改为：D2=0.1*(1-0.2144)/0.2144=0.3664	
		第二次分类 h3
		|           +
		|                      -
		|       +      +
		------------------------------------
		|      -
		|+          -
		|
		| +             	-
		|   -
		--------------------------	
		上边是+类 ，下边是-类，显然 上边有1个非 + 类的 -样本。下边有2个非 - 类的 +样本。
		第二次分类后，样本集的权值和为 0.1*4 + 0.2333*3 + 0.2144*3 = 2.1991			
		这次弱分类的权值误差： e1 = （0.1+0.1+0.1）/2.1991=0.1365
		这次分类权重：a1 = 1/2*ln（1-e1/e1）=1/2*ln(1-0.1365/0.1365)=0.9226
		这时被正确分类的点权值不变,三个错误点权值更改为：D3=0.1*(1-0.1365)/0.1365=0.6326
		最终分类器可为各个弱分类的权重叠加：0.41*h1 + 0.64*h2 + 0.92*h3
		|            +       | 
		|                    |   -
		|        +      +    |
		|   ------------------
		|   |   -            
		|+  |        -       
		|   |                
		| + |                     -
		|   |-               
		----|----------------------------
		                    
		左下角： h1h2都表示+类，h3表示-类，因为 0.41+0.64 > 0.92 所以表示为+类	
		左上角： h1h2h3都表示+类，所以表示为+类	
		上中间： h2h3都表示+类，h2表示-类，因为 0.92+0.64 > 0.41 所以表示为+类
		右上角： h3都表示+类，h1h2表示-类，因为 0.92 < 0.41+0.64 所以表示为-类
		其他类推
	
	K近邻算法 （KNN）					
		kNN分類演算法簡單來說就是要找和新數據最近的K個鄰居，這些鄰居是什麼分類，那麼新數據就是什麼樣的分類。	
		实例，
		有一堆红蓝样品有规则分布在二维平面上，
		有一个新样品处于某个位置，那么这个新样品是什么颜色？
		按照近邻算法估算思维， 以新样品为中心以某一距离为半径的圆里，
		如果包含5个样本，即k=5, 5-近邻 如果红色居多，那么这个新样品估算为红色
		如果包含7个样本，即k=7, 7-近邻 如果蓝色居多，那么这个新样品估算为蓝色
		。。。。

	朴素贝叶斯分类算法
		朴素贝叶斯公式上述已经讨论过
		以下是朴素贝叶斯分类算法：
		1,设置 x = {a1,a2,a3,a4,,,}属性组合,而每个a为x的一个特征属性。每个属性是相互独立的
		  即 P（x）= P（a1）P（a2）P（a3）P（a4）,,
		2,有一个样本集 C = {y1，y2，y3，y4，y5，y6，y7，，}
		3,算出 P(y1 | x),P(y2 | x),P(y3 | x),,
		  据贝叶斯公式： P(yi | x) = [P(x | yi)*P(yi)] / P(x)
		  P(x | yi)= P(a1 | yi)P(a2 | yi)P(a3 | yi)P(a4 | yi),,,
		  P(yi)就是 yi 在 C 中的分布概率，
		  P（x）= P（a1）P（a2）P（a3）P（a4）
		  注意区分 P（x），P(yi) 的底层意义，P（x）相当与P(ABCDE)，而P(yi)相当于P(A)
		4,a1,a2,a3,,,指定值下，P（x）就是一个定值，表示这些指定属性值，组合出现的概率
		  P(yi | x) 也就是在这些指定属性组合必然出现的条件下，yi也出现的概率
		  那么 max{P(y1 | x)，P(y2 | x)，P(y3 | x)，P(y4 | x)，，}得到P(yi | x)
		  这个P(yi | x)概率最大，所以我们可以这样估算说，这个yi出现时，必然伴随这 这个指定的x属性组合
		  由于，P(yi | x) = [P(x | yi)*P(yi)] / P(x) ，分子相同，
		  所以 P(x | yi)*P(yi) 最大，P(yi | x)就最大
		例子：
		tom有好多车，每天都随机开不同颜色的车出门，现在讨论一个问题，
		tom开啥颜色的车出门时，我们就知道这天是个秋高气爽的好天气？
		开车颜色，与天气貌似没有关联，却可以通过贝叶斯分类的的到很好的估计！！
		Day Outlook Temperature Humidity Wind car-color
		D1 Sunny cool High Strong red
		D2 Sunny cool High Strong red
		D3 Overcast Hot High Weak white
		D4 Rain Mild High Weak blue
		D5 Rain Cool Normal Weak red
		D6 Rain Cool Normal Strong blue
		D7 Overcast Cool Normal Strong red
		D8 Sunny Mild High Weak red
		D9 Sunny Cool Normal Weak white
		D10 Rain Mild Normal Weak blue
		D11 Sunny Mild Normal Strong red
		D12 Overcast Mild High Strong red
		D13 Overcast Hot Normal Weak white
		D14 Rain Mild High Strong white
		属性组合 x：{Outlook， Temperature， Humidity， Wind，}
		样本集 C = （red，white，blue）
		属性组合指定了秋高气爽，即对应 x = {Outlook=sunny,Temperature=cool,Humidity=high,Wind=strong}
		还有：P（y1）= P（red）=7/14=0.5
		     P（y2）= P（white）=4/14=0.2857
		     P（y3）= P（blue）=3/14=0.2143
		     p（a1 | y1）=p（sunny | red）= 3/7
		     p（a2 | y1）=p（cool | red）= 3/7	
		     p（a3 | y1）=p（high | red）= 3/7
		     p（a4 | y1）=p（strong | red）= 5/7
		     p（a1 | y2）=p（sunny | white）= 1/7
		     p（a2 | y2）=p（cool | white）= 1/7	
		     p（a3 | y2）=p（high | white）= 2/7
		     p（a4 | y2）=p（strong | white）= 1/7		
		     p（a1 | y3）=p（sunny | blue）= 0/7
		     p（a2 | y3）=p（cool | blue）= 1/7	
		     p（a3 | y3）=p（high | blue）= 1/7
		     p（a4 | y3）=p（strong | blue）= 1/7
		然后：P(x | y1)*P(y1)=p（a1 | y1）p（a2 | y1）p（a3 | y1）p（a4 | y1）P(y1)=0.028
		     P(x | y2)*P(y2)=0.00023	
		     P(x | y3)*P(y3)=0
		发现 P(x | y1)*P(y1) 值最大，表示秋高气爽的日子里，tom有 2.8% 是开着红色车的
		在这里也就粗略近似为，tom开红车出门时，那天必然是秋高气爽

	CART：CART演算法又被稱為決策樹(Decision tree) 

	ID3 决策书算法 
		特点： 选择 信息增益 最大的特征作为结点的特征		
		天气与打球 的例子说明:
		Day Outlook Temperature Humidity Wind playball
		D1 Sunny hot High Weak no
		D2 Sunny hot High Strong no
		D3 Overcast Hot High Weak yes
		D4 Rain Mild High Weak yes
		D5 Rain Cool Normal Weak yes
		D6 Rain Cool Normal Strong no
		D7 Overcast Cool Normal Strong yes
		D8 Sunny Mild High Weak no
		D9 Sunny Cool Normal Weak yes
		D10 Rain Mild Normal Weak yes
		D11 Sunny Mild Normal Strong yes
		D12 Overcast Mild High Strong yes
		D13 Overcast Hot Normal Weak yes
		D14 Rain Mild High Strong no		
		玩不玩球是最终决策点内容，决策点的熵 
			Entropy（playball）= Entropy（9,5） 	//（5个no 9个yes） 	
					   = Entropy（0.64,0.36）
					   = −( 0.64 * log_2(0.64) ) − ( 0.36 * log_2(0.36) ) 		
					   = 0.94
		讨论 Outlook 特征与playball关系 ：
					playvball-yes	playball-no	sum
			sunny		3		2		5
			overcast	4		0		4
			rainy		2		3		5
			得到的 加权信息熵：
			Entropy（playball，outlook）= P（sunny）Entropy（3,2）+P（overcast）Entropy（4,0）+P（rainy）Entropy（2,3） 	
					   =（5/14）*0.971 + (4/14)*0 + (5/14)*0.971
					   = 0.693
			计算采用Outlook这个特征来做划分时的信息增益:
			G(PlayBall,Outlook) = Entropy(PlayBall)−Entropy(PlayBall,Outlook) = 0.94−0.693 = 0.247
		同理继续讨论 Temperature Humidity Wind 特征与playball关系：
			G(PlayBall,Temperature) =0.029
			G(PlayBall,Humidity) = 0.152
			G(PlayBall,Wind) = 0.048
		取其中具有最大信息增益的特征来作为划分的标准：即 Outlook 为第一个分支点，有三条支路：
				outlook
			    /      |      \
			sunny 	overcast  rain
			  /        |        \
			每条支路都有新的样本表对应：
			sunny：
				D1 hot High Weak no
				D2 hot High Strong no
				D8 Mild High Weak no
				D9 Cool Normal Weak yes
				D11 Mild Normal Strong yes
			overcast：
				D3 Hot High Weak yes
				D7 Cool Normal Strong yes
				D12 Mild High Strong yes
				D13 Hot Normal Weak yes
			rain：
				D4 Mild High Weak yes
				D5 Cool Normal Weak yes
				D6 Cool Normal Strong no
				D10 Mild Normal Weak yes
				D14 Mild High Strong no	
		overcast分支：playball都为yse，所以这份分支样本表 熵为0,直接输出yes
		sunny分支：从sunny支线样本表重新算出Entropy（playball），
			   从sunny支线样本表重新讨论Temperature Humidity Wind 特征与playball关系，即信息增益
			   取其中具有最大信息增益的特征来作为划分的标准，这里是 Humidity特征
		rain分支：从rain支线样本表重新算出Entropy（playball），
			  从rain支线样本表重新讨论Temperature Humidity Wind 特征与playball关系，即信息增益
			  取其中具有最大信息增益的特征来作为划分的标准，这里是 wind特征
		根据以上内容继续构建决策树：
						outlook
				    /	           |		  \
				sunny	 	overcast 	 rain
				  /     	   |       	    \			
			      Humidity	      playball-yes	   wind
   		   	      /      \			        /        \
			   hight     nomal		     strong	weak
			    /          \		       /	   \
		对应的下级分支样本表：
			humidity-hight：	
				D1 hot Weak no
				D2 hot Strong no
				D8 Mild Weak no
			humidity-nomal：				
				D9 Cool Weak yes
				D11 Mild Strong yes
			wind-strong：
				D6 Cool Normal no
				D14 Mild High no
			wind-weak：
				D4 Mild High yes
				D5 Cool Normal yes
				D10 Mild Normal yes
			所有下级分支对应 playball都只有一个内容 所以熵都为0
		根据以上内容最终构建的决策树为：
						outlook
				    /	           |		  \
				sunny	 	overcast 	 rain
				  /     	   |       	    \			
			      Humidity	      playball-yes	   wind
   		   	      /      \			        /        \
			   hight     nomal		     strong	weak
			    /          \		       /	   \			
		      playball-no  playball-yes          playball-no   playball-yes
		根据这个决策树：
			下次输入一条天气信息，我们就可以通过决策树来判断 打不打球了

	CD4.5 决策树：
		特点：基于id3改进的，区别在选择 信息增益率 最大的特征作为结点的特征
		以上述为例子继续讨论：
		玩不玩球是最终决策点内容，决策点的熵 
		Entropy（playball）= 0.94 
		讨论 Outlook 特征与playball关系 ：
					playvball-yes	playball-no	sum
			sunny		3		2		5
			overcast	4		0		4
			rainy		2		3		5
			得到的 加权信息熵：
			Entropy（playball，outlook）= P（sunny）Entropy（3,2）+P（overcast）Entropy（4,0）+P（rainy）Entropy（2,3） 	
					   =（5/14）*0.971 + (4/14)*0 + (5/14)*0.971
					   = 0.693
			计算采用Outlook这个特征来做划分时的信息增益:
			G(PlayBall,Outlook) = Entropy(PlayBall)−Entropy(PlayBall,Outlook) = 0.94−0.693 = 0.247
			I（sunny,overcast,rainy）=-5/14log(5,14) - 4/14log(4,14) - 5/14log(5,14)
						 =-5/14log_2(5/14) - 4/14log_2(4/14) - 5/14log_2(5/14)
						 
			信息增益率：Gain-ratio（A）=G(PlayBall,Outlook)/I（sunny,overcast,rainy）
						  =0.247/I（sunny,overcast,rainy）
		同理继续讨论 Temperature Humidity Wind 特征与playball关系(信息增益率)：
			选取信息增益率 最大的特征来作为划分的标准
			。。。。。
	ID3与CD4.5的使用意义区分：
		ID3使用信息增益Info-Gain在面对类别较少的离散数据时效果较好，上例中的outlook、temperature等数据都是离散数据，
		而且每个类别都有一定数量的样本，这种情况下使用ID3与C4.5的区别并不大。
		但如果面对连续的数据（如体重、身高、年龄、距离等），或者每列数据没有明显的类别之分（最极端的例子的该列所有数据都独一无二），
		这种时候CD4.5的的效果就更为突出。

	CART决策树算法： 
		CART假设决策树是二叉树，即二分支！内部结点特征的取值为“是”和“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支，
		而 ID3和CD4.5都可以多分支，
		cart关键是 gini系数的使用！！
		是否拖欠贷款例子：
		序号  有房子 婚姻 年收入  是否拖欠贷款
		1 yes single 125k no
		2 no married 100k no
		3 no single 70k no
		4 yes married 120k no
		5 no divorced 95k yes
		6 no married 60k no
		7 yes divorced 220k no
		8 no single 85k yes
		9 no married 75k no
		10 no single 90k yes	
		最后的决策点是 是否是否拖欠贷款。
		首先，计算是否拖欠贷款 gini系数
			Gini(是否拖欠贷款)=1 − (3/10)^2 − (7/10)^2 = 0.42
		分别计算 有房子 婚姻 年收入 它们的 Gini系数增益,
		有房子 Gini系数增益 Δ：
				有房yes  有房no
			拖欠      0       3
			没拖欠    3       4
			Gini(左子节点)=1 − (0/3)^2 − (3/3)^2 = 0
			Gini(右子节点)=1 − (3/7)^2 − (4/7)^2 = 0.4898
			Δ{是否有房}=0.42 − 7/10*0.4898 − 3/10*0 =0.077
		婚姻 Gini系数增益 Δ：
			由于cart是 2叉树结构，对于婚姻这种三态（甚至多态）的情况下，要这样修改
			分成多个两组，分别算出 Gini系数增益 Δ：
			{married} | {single,divorced}
				Δ{婚姻状况}=0.42 − 4/10*0 − 6/10*[ 1 − (3/6)^2 − (3/6)^2 ]=0.12
			{single} | {married,divorced}时，
				Δ{婚姻状况}=0.42 − 4/10*0.5 − 6/10*[ 1 − (1/6)^2 − (5/6)^2 ]=0.053
			{divorced} | {single,married}时，
				Δ{婚姻状况}=0.42 − 2/10*0.5 − 8/10*[ 1 − (2/8)^2 − (6/8)^2 ]=0.02
			根据婚姻状况属性来划分根节点时取Gini系数增益最大的分组作为划分结果，
			也就是{married} | {single,divorced}
		年收入属性 Gini系数增益 Δ：
			由于cart是 2叉树结构，对于年收入属性这种连续数值的情况下，则这样修改
			把年收入属性 重新排列数据，然后 分成多个两组，分别算出 Gini系数增益 Δ：
			分组例如当面对年收入为60和70这两个值时，我们算得其中间值为65。倘若以中间值65作为分割点。
			Gini(左子节点)作为年收入小于65的样本，Gini(右子节点)表示年收入大于等于65的样本，
			于是则得Gini系数增益为 ：
				Δ(年收入) = 0.42 − 1/10*0 − 9/10*[ 1 − (6/9)*2 − (3/9)*2 ]=0.02
			    是否拖欠 no   no    no     yes   yes    yes   no     no      no      no  
			      年收入 60   70    75     85    90     95    100    120     125     220
			      相邻值   65   72.5    80   87.7   92.5   97.5   110    122.5   172.5
			GIni系数增益  0.02  0.045  0.077 0.003  0.02   0.12   0.077  0.045   0.02
			同样取取Gini系数增益最大的分组作为划分结果，
			也就是 97.5 相邻值 的分组
		建立分叉树：
			计算知道，三个属性划分根节点的增益最大的有两个：年收入属性和婚姻状况，他们的增益都为0.12。
			此时，选取首先出现的属性作为第一次划分。
					婚姻
				/		  \ 
			     married		single,divorced
			      /                     \
			     no                     ...
		得到分支样本表
			序号 有房子 年收入  是否拖欠贷款
			1 yes 125k no
			3 no 70k no
			5 no  95k yes
			7 yes 220k no
			8 no 85k yes
			10 no 90k yes	
		同理，计算新的 是否拖欠贷款 gini系数
			Gini(是否拖欠贷款)=1 − (3/6)^2 − (3/6)^2 = 0.5
		同理，有房子 Gini系数增益 Δ：	
			Δ{是否有房}=0.5 − 4/6*[ 1 − (3/4)^2 − (1/4)^2 ] − 2/6*0 =0.25
		同理，年收入属性 Gini系数增益 Δ：
			    是否拖欠 no   yes   yes    yes   no     no 
			      年收入 70   85    90     95    125    220
			      相邻值   77.5  87.7  92.5   110   172.5
			GIni系数增益   0.1   0.25  0.05   0.25  0.1
		建立分叉树：
			计算知道，两个属性划分根节点的增益最大的有两个：年收入属性和有房子，他们的增益都为 0.25。
			此时，选取首先出现的属性作为第一次划分。
					婚姻
				/		  \ 
			     married		single,divorced
			      /                     \
			     no                    有房子
						/	   \
					      yes	   no
					      /              \
					     no		    ....
		得到分支样本表
			序号 年收入  是否拖欠贷款
			3 70k no
			5 95k yes
			8 85k yes
			10 90k yes
			可以看见， 年收入>70k时，按照规则，取回77与85间中值 77.5 拖欠贷款。所以得到最后建立的二叉树
					婚姻
				/		  \ 
			     married		single,divorced
			      /                     \
			     no                    有房子
						/	   \
					      yes	   no
					      /              \
					     no		    年收入
							  /	  \
						       <=77.5    >=77.5	
							/           \
						       no           yes
		cart的决策树便建立好了，然后是 关于过拟合与剪枝
			决策树很容易发生过拟合，对train数据集适应得太好，反而在test数据集上表现得不好
			对模型剪枝，是降低过拟合的一种做法
			剪枝操作（待续）

	蒙特卡罗算法：
		并不是一种算法的名称，而是一类随机方法的统称
		举个例子：
			假如筐里有100个苹果，让我每次闭眼拿1个，挑出最大的。
			于是我随机拿1个，再随机拿1个跟它比，留下大的，再随机拿1个……我每拿一次，
			留下的苹果都至少不比上次的小。拿的次数越多，挑出的苹果就越大，
			但我除非拿100次，否则无法肯定挑出了最大的。
			这个挑苹果的算法，就属于蒙特卡罗算法——尽量找好的，但不保证是最好的。
		对比而拉斯维加斯算法：
			假如有一把锁，给我100把钥匙，只有1把是对的。
			于是我每次随机拿1把钥匙去试，打不开就再换1把。
			我试的次数越多，打开（最优解）的机会就越大，
			但在打开之前，那些错的钥匙都是没有用的。
			这个试钥匙的算法，就是拉斯维加斯的——尽量找最好的，但不保证能找到。
		这两类随机算法之间的选择，往往受到问题的局限。
			如果问题要求在有限采样内，必须给出一个解，但不要求是最优解，那就要用蒙特卡罗算法。
			反之，如果问题要求必须给出最优解，但对采样没有限制，那就要用拉斯维加斯算法。
		对于机器围棋程序而言，
			因为每一步棋的运算时间、堆栈空间都是有限的，而且不要求最优解，所以ZEN涉及的随机算法，肯定是蒙特卡罗式的。
			机器下棋的算法本质都是搜索树，围棋难在它的树宽可以达到好几百（国际象棋只有几十）。
			在有限时间内要遍历这么宽的树，就只能牺牲深度（俗称“往后看几步”），
			但围棋又是依赖远见的游戏，甚至不仅是看“几步”的问题。
			所以，要想保证搜索深度，就只能放弃遍历，改为随机采样
			这就是为什么在没有MCTS（蒙特卡罗搜树）类的方法之前，机器围棋的水平几乎是笑话。
	强化学习（RL）
		不停地重复执行，获得反馈，直到收敛到最佳效果
		细看下来，分明与监督学习（SL），无监督学习（UL）是不同的类别，RL更像控制系统家族里的。
		是的，RL里流着控制的血液，披着机器学习的外衣，这是因为它需要data，需要training以此来支持决策。
		RL可以decision-making，不同于决策树之类的决策（称为预测比较好），是控制角度的决策，
		意味着就有失误，伴随着收益与惩罚（股票，博弈，游戏得分等等）。
		细一点来说，RL与SL的区别有：
			喂数据的方式不同：强化学习（RL）的数据是序列的、交互的、并且还是有反馈的（Reward）-【MDP]。
			与监督学习（SL）在优化目标的表现形式的根本差异：
				RL是一个决策模型。
				SL更偏向模式挖掘，低阶的函数逼近与泛化。
				RL是agent自己去学习。
				SL是跟着programmer的idea在收敛。
				RL的target是估计得来的，符合bellman等式，
				SL的target是fixed label；
				RL可以融合SL来训练，RL还可以自己博弈来生成样本。[交互特性，也可以放到第一点中]
				RL可以进行lifelong形式的学习。
				RL有“生命”的【你可能也不知道你训练出来的模型到底能干什么】，
				SL没有“生命”。
强化学习方法汇总：
	model-free RL（不理解环境）不断重复直接执行，等待现实反馈，			
		方法有：Q-learning，sarsa，policy-Gradients	
	model-base RL（理解环境）： 比较上面的方法，在这里多了一个构造虚拟环境的步骤，先在虚拟环境中实现后评估是否将要执行的行为！！
		然后再在真实世界上执行，然后等待现实反馈
		方法也是有：Q-learning，sarsa，policy-Gradients	

	基于概率（Police-based RL）：根据概率，随机执行动作，概率越大的动作，执行的可能性越高
		对于连续动作来说，这个思路效果更好
		方法有police-gradients
	基于价值（Value）：根据价值，执行价值最高的动作。
		方法有Q-learning，sarsa

	回合更新（Monte-Carlo update）：
		游戏结束后，才更新学习数据
		方法有基础版police-gradients，Monte-Carlo-learning
	单步更新（Temporal-Difference update）：
		游戏中每一步，都更新学习数据
		方法有Q-learning，sarsa，升级版police-gradients

	在线学习（on-policy）
		边执行边学习
		方法有sarsa（入），sarsa
	离线学习（off-policy）
		把执行的记录全程记录下，之后在学习，同样可以选着看着别人的执行记录学习	
		方法有Deep Q network，Q-learning

复习;

	namalize正则化是在 activation激励 之前 吧输出结果规范到一个区间里，然后再activation激励，这样大多数输出值不会在0和1两个极限饱和值上，
		注意是batch marmalize ，跟batch 有关系，不是简单的narmalize，要看理论式子
	activation/激励是把输出的结果限制在 0-1之间，但是很多激励后的结果都在0或则1附近的饱和区域,不利于学习的梯度传递，
		容易梯度消失或爆炸，所以在激励前先 namalize正则化
		有Relu 等等 	
	optimizer优化器，优化学习率 包括什么Adma， 还有 dropout什么的
		dropout不算是一个正规正矩的优化器，他的工作是，每次网络工作时，都随机抛弃一部分的神经元的作用，从而避免过度拟合
		还有一个叫分支 叫正规化操作
		（例如L1,L2regulation正规化，是处理 误差/交叉熵的一种方法，能很好规避过拟合的发生）
	卷积和池化区别：卷积是通过卷积核过滤图片得到一张特征图，不同卷积核过滤同一张图片得到不同特征图
		       池化是把卷积得到特征图划分多个区域，然后从每个区域中又选出最有意义的特征值，比如说区域里的最大值，
		       本质上卷积和池化操作都是差不多，卷积的过滤出特征值和池化的选出特征值感觉差不多的操作，
		       但是卷积核是轮寻步进区域的，而池化是操作的是，把图片划分的多个区域！
	RNN网络要再学习！！，深入底层那种

Q-learning：（未总结）
sarsa：
sarsa（入）：
Deep Q-Learing Net（DQN）：
police-gradients：
Actor Critic：组合了police-gradients Q-learning 
Deep Deterministic Policy Gradient (DDPG)：Actor Critic + DQN
A3C (Asynchronous Advantage Actor-Critic)：相当于多个Actor Critic各自独立学习，又共享学习信息，（类比多进程并行工作）




PyTorch：

tensorflow：
	loss 跟 cross-entropy（向量loss）
	dropout
	注意 names_scope 和 varible_scope 区别和使用规则

	

自编码autoencoder：
	无监督学习过程例子
	一张图片，经过encoder 压缩出一串数据，然后经过decoder自画图片，再encoder得到一串数据，
	前后两两串数据应该几乎一样，不一样的话就有误差，经过误差返回传导修改encoder和decoder学习模型！！
	又或者，直接对比两张图片所有像素信息的误差，经过误差返回传导修改encoder和decoder学习模型！！

GAN：
	谁随机生成然后与样本对比，然后学习，直到与样品越来越像
	训练一个网络专门生成样本
	训练另一个网路比较 生成样本 与实际样本，
	取得对应误差 反向更新这两个网络。
	直到 生成样本与 实际样本越来越相似

迁移学习
	就是用别人训练好的网络，去头去尾，根据需求组合成新网络，减少更多训练时间

交叉验证：
	同一堆样品，做多个回合的训练，
	每一回合有计划或随机分成训练组和验证组，用训练组训练，用验证组验证

scikit-learning：
	很多模型都建立好，简单填参数使用的库，还有很多模拟建立样本数据的函数

theano：
	比tensorflow 更学术
	莫烦讨论的 分类例子的算法和我们认识的cnn 分类算法不一样
	莫烦那输出是一个数，是一个0和1的二值分类
	而我们认识的cnn 分类算法输出是一个向量，是一个多类分类，样品属于哪一类，对应输出向量的那一维为1,其他维为0
	所谓one-hot，就是诸如上述的 某一维为1其他为0的向量

keras：
	以tensorflow或 theano 做 底层基础的高级操作库
	需要清楚当前时刻的keras是以那个做底层，
	直接import keras 可以看到相关信息，不是自己需要的底层基础要及时修改配置
	
RL：

Q-learing：
	

理论学习路线：莫烦PyTorch ->莫烦tensoeflow（）->莫烦sciki-learning-> 莫烦theano-> 莫烦 kera
	     莫烦RL强化学习（现在）


前馈网络对于机器学习的从业者是极其重要的。它们是许多重要商业应用的基
础。例如,用于对照片中的对象进行识别的卷积神经网络就是一种专门的前馈网络。
前馈网络是通往循环网络之路的概念基石,后者在自然语言的许多应用中发挥着巨
大作用。
前馈神经网络被称作 网络(network)是因为它们通常用许多不同函数复合
在 一 起 来 表 示。该 模 型 与 一 个 有 向 无 环 图 相 关 联, 而 图 描 述 了 函 数 是 如 何 复
合 在 一 起 的。例 如, 我 们 有 三 个 函 数 f (1) , f (2) 和 f (3) 连 接 在 一 个 链 上 以 形 成
f (x) = f (3) (f (2) (f (1) (x)))。这些链式结构是神经网络中最常用的结构。在这种情况
下,f (1) 被称为网络的 第一层(first layer)
,f (2) 被称为 第二层(second layer),以
此类推。链的全长称为模型的 深度(depth)。正是因为这个术语才出现了 ‘‘深度学
习’’ 这个名字。前馈网络的最后一层被称为 输出层(output layer)。在神经网络训练
的过程中,我们让 f (x) 去匹配 f ∗ (x) 的值。训练数据为我们提供了在不同训练点上
取值的、含有噪声的 f ∗ (x) 的近似实例。每个样本 x 都伴随着一个标签 y ≈ f ∗ (x)。
训练样本直接指明了输出层在每一点 x 上必须做什么;它必须产生一个接近 y 的值。
145第六章
146
深度前馈网络
但是训练数据并没有直接指明其他层应该怎么做。学习算法必须决定如何使用这些
层来产生想要的输出,但是训练数据并没有说每个单独的层应该做什么。相反,学
习算法必须决定如何使用这些层来最好地实现 f ∗ 的近似。因为训练数据并没有给出
这些层中的每一层所需的输出,所以这些层被称为 隐藏层(hidden layer)。
最后,这些网络被称为神经网络是因为它们或多或少地受到神经科学的启
发。网络中的每个隐藏层通常都是向量值的。这些隐藏层的维数决定了模型的 宽度
(width)。向量的每个元素都可以被视为起到类似一个神经元的作用。除了将层想
象成向量到向量的单个函数,我们也可以把层想象成由许多并行操作的 单元(unit)
组成,每个单元表示一个向量到标量的函数。每个单元在某种意义上类似一个神经
元,它接收的输入来源于许多其他的单元,并计算它自己的激活值。使用多层向量值
表示的想法来源于神经科学。用于计算这些表示的函数 f (i) (x) 的选择,也或多或少
地受到神经科学观测的指引,这些观测是关于生物神经元计算功能的。然而,现代
的神经网络研究受到更多的是来自许多数学和工程学科的指引,并且神经网络的目
标并不是完美地给大脑建模。我们最好将前馈神经网络想成是为了实现统计泛化而
设计出的函数近似机,它偶尔从我们了解的大脑中提取灵感,但并不是大脑功能的
模型。
为了扩展线性模型来表示 x 的非线性函数,我们可以不把线性模型用于 x 本身,
而是用在一个变换后的输入 φ(x) 上,这里 φ 是一个非线性变换。同样,我们可以
使用第 5.7.2 节中描述的核技巧,来得到一个基于隐含地使用 φ 映射的非线性学习算
法。我们可以认为 φ 提供了一组描述 x 的特征,或者认为它提供了 x 的一个新的表
示。深度学习的策略是去学习 φ。在这种方法中,我们有一个模型 y = f (x; θ, w) = φ(x; θ)'⊤ w

机器学习中的一个核心问题是设计不仅在训练数据上表现好,并且能在新输入
上泛化好的算法。在机器学习中,许多策略显式地被设计来减少测试误差(可能会
以增大训练误差为代价)。这些策略被统称为正则化。
在第 5.2.2 节中,我们将正则化定义为 ‘‘对学习算法的修改——旨在减少泛化误
差而不是训练误差’’
在深度学习的背景下,大多数正则化策略都会对估计进行正则化。估计的正则
化以偏差的增加换取方差的减少。

????????????????????





